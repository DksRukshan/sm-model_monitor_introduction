{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f21e958",
   "metadata": {
    "papermill": {
     "duration": 0.021009,
     "end_time": "2022-04-18T00:13:14.040150",
     "exception": false,
     "start_time": "2022-04-18T00:13:14.019141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Amazon SageMaker Model Monitor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21e958",
   "metadata": {
    "papermill": {
     "duration": 0.021009,
     "end_time": "2022-04-18T00:13:14.040150",
     "exception": false,
     "start_time": "2022-04-18T00:13:14.019141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook shows how to:\n",
    "\n",
    "• Host a machine learning model in Amazon SageMaker and capture inference requests, results, and metadata \n",
    "\n",
    "• Analyze a training dataset to generate baseline constraints\n",
    "\n",
    "• Monitor a live endpoint for violations against constraints\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker provides every developer and data scientist with the ability to build, train, and deploy machine learning models quickly. Amazon SageMaker is a fully-managed service that encompasses the entire machine learning workflow. You can label and prepare your data, choose an algorithm, train a model, and then tune and optimize it for deployment. You can deploy your models to production with Amazon SageMaker to make predictions and lower costs than was previously possible.\n",
    "\n",
    "In addition, Amazon SageMaker enables you to capture the input, output and metadata for invocations of the models that you deploy. It also enables you to analyze the data and monitor its quality. In this notebook, you learn how Amazon SageMaker enables these capabilities.\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook uses an hourly monitor, so it takes between 30-90 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [PART A: Capturing real-time inference data from Amazon SageMaker endpoints](#PART-A:-Capturing-real-time-inference-data-from-Amazon-SageMaker-endpoints)\n",
    "1. [PART B: Model Monitor - Baselining and continuous monitoring](#PART-B:-Model-Monitor---Baselining-and-continuous-monitoring)\n",
    "    1. [Constraint suggestion with baseline/training dataset](#1.-Constraint-suggestion-with-baseline/training-dataset)\n",
    "    1. [Analyze collected data for data quality issues](#2.-Analyze-collected-data-for-data-quality-issues)\n",
    "\n",
    "## Setup\n",
    "\n",
    "To get started, make sure you have these prerequisites completed:\n",
    "\n",
    "* Specify an AWS Region to host your model.\n",
    "* An IAM role ARN exists that is used to give Amazon SageMaker access to your data in Amazon Simple Storage Service (Amazon S3).\n",
    "* Use the default S3 bucket to store the data used to train your model, any additional model data, and the data captured from model invocations. For demonstration purposes, you are using the same bucket for these. In reality, you might want to separate them with different security policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06059fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:13:14.089492Z",
     "iopub.status.busy": "2022-04-18T00:13:14.088656Z",
     "iopub.status.idle": "2022-04-18T00:13:15.821945Z",
     "shell.execute_reply": "2022-04-18T00:13:15.821505Z"
    },
    "isConfigCell": true,
    "papermill": {
     "duration": 1.760865,
     "end_time": "2022-04-18T00:13:15.822056",
     "exception": false,
     "start_time": "2022-04-18T00:13:14.061191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 10:24:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 10:24:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=774238;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=404129;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/dks.rukshan/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 10:24:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 10:24:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=129238;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271240;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Bucket: sagemaker-us-east-1-266735799838\n",
      "Capture path: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/datacapture\n",
      "Report path: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/reports\n",
      "Preproc Code path: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/code/preprocessor.py\n",
      "Postproc Code path: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/code/postprocessor.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "import os\n",
    "\n",
    "sm_session = sagemaker.Session()\n",
    "region = sm_session.boto_region_name\n",
    "\n",
    "role = 'arn:aws:iam::266735799838:role/amazonsagemaker-role'\n",
    "\n",
    "bucket = sm_session.default_bucket()\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "prefix = \"sagemaker/ModelMonitor\"\n",
    "default_bucket_prefix = sm_session.default_bucket_prefix\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    prefix = f\"{default_bucket_prefix}/{prefix}\"\n",
    "\n",
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "reports_prefix = \"{}/reports\".format(prefix)\n",
    "s3_report_path = \"s3://{}/{}\".format(bucket, reports_prefix)\n",
    "code_prefix = \"{}/code\".format(prefix)\n",
    "s3_code_preprocessor_uri = \"s3://{}/{}/{}\".format(bucket, code_prefix, \"preprocessor.py\")\n",
    "s3_code_postprocessor_uri = \"s3://{}/{}/{}\".format(bucket, code_prefix, \"postprocessor.py\")\n",
    "\n",
    "print(\"Capture path: {}\".format(s3_capture_upload_path))\n",
    "print(\"Report path: {}\".format(s3_report_path))\n",
    "print(\"Preproc Code path: {}\".format(s3_code_preprocessor_uri))\n",
    "print(\"Postproc Code path: {}\".format(s3_code_postprocessor_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e9a54",
   "metadata": {
    "papermill": {
     "duration": 0.021449,
     "end_time": "2022-04-18T00:13:15.865605",
     "exception": false,
     "start_time": "2022-04-18T00:13:15.844156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PART A: Capturing real-time inference data from Amazon SageMaker endpoints\n",
    "Create an endpoint to showcase the data capture capability in action.\n",
    "\n",
    "### Upload the pre-trained model to Amazon S3\n",
    "This code uploads a pre-trained XGBoost model that is ready for you to deploy. This model was trained using the XGB Churn Prediction Notebook in SageMaker. You can also use your own pre-trained model in this step. If you already have a pretrained model in Amazon S3, you can add it instead by specifying the s3_key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee26d288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:13:15.920803Z",
     "iopub.status.busy": "2022-04-18T00:13:15.912381Z",
     "iopub.status.idle": "2022-04-18T00:13:16.050565Z",
     "shell.execute_reply": "2022-04-18T00:13:16.050961Z"
    },
    "papermill": {
     "duration": 0.16406,
     "end_time": "2022-04-18T00:13:16.051105",
     "exception": false,
     "start_time": "2022-04-18T00:13:15.887045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:35:08] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:35:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=522578;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=152149;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_file = open(\"model/xgb-churn-prediction-model.tar.gz\", \"rb\")\n",
    "s3_key = os.path.join(prefix, \"xgb-churn-prediction-model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_key).upload_fileobj(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad4a66",
   "metadata": {
    "papermill": {
     "duration": 0.021593,
     "end_time": "2022-04-18T00:13:16.094614",
     "exception": false,
     "start_time": "2022-04-18T00:13:16.073021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Deploy the model to Amazon SageMaker\n",
    "Start with deploying a pre-trained churn prediction model. Here, you create the model object with the image and model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad19f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:13:16.143192Z",
     "iopub.status.busy": "2022-04-18T00:13:16.142700Z",
     "iopub.status.idle": "2022-04-18T00:13:16.156473Z",
     "shell.execute_reply": "2022-04-18T00:13:16.156847Z"
    },
    "papermill": {
     "duration": 0.040689,
     "end_time": "2022-04-18T00:13:16.156984",
     "exception": false,
     "start_time": "2022-04-18T00:13:16.116295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:36:01] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Defaulting to only available Python version: py3                     <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#610\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">610</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:36:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Defaulting to only available Python version: py3                     \u001b]8;id=755479;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=546690;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#610\u001b\\\u001b[2m610\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Defaulting to only supported image scope: cpu.                       <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#534\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Defaulting to only supported image scope: cpu.                       \u001b]8;id=622572;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=632451;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#534\u001b\\\u001b[2m534\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "model_name = \"DEMO-xgb-churn-pred-model-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = \"https://{}.s3-{}.amazonaws.com/{}/xgb-churn-prediction-model.tar.gz\".format(\n",
    "    bucket, region, prefix\n",
    ")\n",
    "\n",
    "image_uri = retrieve(\"xgboost\", region, \"0.90-1\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7b61e",
   "metadata": {
    "papermill": {
     "duration": 0.02197,
     "end_time": "2022-04-18T00:13:16.200979",
     "exception": false,
     "start_time": "2022-04-18T00:13:16.179009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To enable data capture for monitoring the model data quality, you specify the new capture option called `DataCaptureConfig`. You can capture the request payload, the response payload or both with this configuration. The capture config applies to all variants. Go ahead with the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a8f85c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:13:16.258005Z",
     "iopub.status.busy": "2022-04-18T00:13:16.249135Z",
     "iopub.status.idle": "2022-04-18T00:20:48.394644Z",
     "shell.execute_reply": "2022-04-18T00:20:48.395055Z"
    },
    "papermill": {
     "duration": 452.17232,
     "end_time": "2022-04-18T00:20:48.395194",
     "exception": false,
     "start_time": "2022-04-18T00:13:16.222874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName=DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:37:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:37:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=693761;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=830014;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=761045;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=956522;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: sagemaker-xgboost-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-20-06-07-30-626    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: sagemaker-xgboost-\u001b[1;36m2025\u001b[0m-02-20-06-07-30-626    \u001b]8;id=223776;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=120012;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:37:32] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:37:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=427494;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=630142;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m30\u001b[0m                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:37:33] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:37:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=966769;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=373019;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m30\u001b[0m                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "endpoint_name = \"DEMO-xgb-churn-pred-model-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed7979",
   "metadata": {
    "papermill": {
     "duration": 0.025376,
     "end_time": "2022-04-18T00:20:48.446074",
     "exception": false,
     "start_time": "2022-04-18T00:20:48.420698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Invoke the deployed model\n",
    "\n",
    "You can now send data to this endpoint to get inferences in real time. Because you enabled the data capture in the previous steps, the request and response payload, along with some additional metadata, is saved in the Amazon Simple Storage Service (Amazon S3) location you have specified in the DataCaptureConfig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848dd92",
   "metadata": {
    "papermill": {
     "duration": 0.025161,
     "end_time": "2022-04-18T00:20:48.496491",
     "exception": false,
     "start_time": "2022-04-18T00:20:48.471330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This step invokes the endpoint with included sample data for about 3 minutes. Data is captured based on the sampling percentage specified and the capture continues until the data capture option is turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d376f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:20:48.562549Z",
     "iopub.status.busy": "2022-04-18T00:20:48.561781Z",
     "iopub.status.idle": "2022-04-18T00:23:51.673621Z",
     "shell.execute_reply": "2022-04-18T00:23:51.674029Z"
    },
    "papermill": {
     "duration": 183.152276,
     "end_time": "2022-04-18T00:23:51.674166",
     "exception": false,
     "start_time": "2022-04-18T00:20:48.521890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 11:41:48] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 11:41:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=242081;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=124051;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test traffic to the endpoint DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30. \n",
      "Please wait...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import time\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())\n",
    "\n",
    "# Get a subset of test data for a quick test\n",
    "!head -180 test_data/test-dataset-input-cols.csv > test_data/test_sample.csv\n",
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "with open(\"test_data/test_sample.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.rstrip(\"\\n\")\n",
    "        response = predictor.predict(data=payload)\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12963ac1",
   "metadata": {
    "papermill": {
     "duration": 0.025961,
     "end_time": "2022-04-18T00:23:51.726250",
     "exception": false,
     "start_time": "2022-04-18T00:23:51.700289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### View captured data\n",
    "\n",
    "Now list the data capture files stored in Amazon S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be89b97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:51.798870Z",
     "iopub.status.busy": "2022-04-18T00:23:51.786388Z",
     "iopub.status.idle": "2022-04-18T00:23:51.965951Z",
     "shell.execute_reply": "2022-04-18T00:23:51.965241Z"
    },
    "papermill": {
     "duration": 0.213801,
     "end_time": "2022-04-18T00:23:51.966129",
     "exception": false,
     "start_time": "2022-04-18T00:23:51.752328",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:01:32] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:01:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=633995;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=109200;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Capture Files:\n",
      "sagemaker/ModelMonitor/datacapture/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/AllTraffic/2025/02/20/06/11-50-426-3bda4ba4-51c6-46d1-821f-c46cb7e2d178.jsonl\n",
      " sagemaker/ModelMonitor/datacapture/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/AllTraffic/2025/02/20/06/12-50-744-122c15f0-49c5-4b0a-988d-815f6de6f2e6.jsonl\n",
      " sagemaker/ModelMonitor/datacapture/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/AllTraffic/2025/02/20/06/13-51-067-58aa28ea-7c44-4e0a-b8d1-5d6e6ad1ee70.jsonl\n",
      " sagemaker/ModelMonitor/datacapture/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/AllTraffic/2025/02/20/06/14-51-616-1164bfb5-c42b-46c1-a906-54cdad80e774.jsonl\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "current_endpoint_capture_prefix = \"{}/{}\".format(data_capture_prefix, endpoint_name)\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b147b62",
   "metadata": {
    "papermill": {
     "duration": 0.027531,
     "end_time": "2022-04-18T00:23:52.029034",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.001503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, view the contents of a single capture file. Here you should see all the data captured in an Amazon SageMaker specific JSON-line formatted file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f20ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:52.088844Z",
     "iopub.status.busy": "2022-04-18T00:23:52.088257Z",
     "iopub.status.idle": "2022-04-18T00:23:52.174071Z",
     "shell.execute_reply": "2022-04-18T00:23:52.173556Z"
    },
    "papermill": {
     "duration": 0.118865,
     "end_time": "2022-04-18T00:23:52.174189",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.055324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"110,0,74.5,117,200.8,98,192.2,101,9.8,7,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.02134251780807972\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"00f7d603-cf2d-4040-98f6-d0a1ef9084ca\",\"inferenceTime\":\"2025-02-20T06:14:51Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"110,27,267.9,103,263.3,74,178.1,106,8.3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.5671311616897583\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"df09613b-66a3-42f5-9e79-3ac611c96883\",\"inferenceTime\":\"2025-02-20T06:14:52Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"94,0,139.4,95,159.1,92,128.2,129,7.7,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.018160536885261536\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"bcf4882f-7a5e-4987-991b-973186072480\",\"inferenceTime\":\"2025-02-20T06:14:54Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"99,28,200.7,88,264.2,116,172.7,102,9.1,5,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,1\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"0.02053365297615528\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"6a33b271\n"
     ]
    }
   ],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cf179",
   "metadata": {
    "papermill": {
     "duration": 0.026714,
     "end_time": "2022-04-18T00:23:52.227979",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.201265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, the contents of a single line is present below in a formatted JSON file so that you can observe a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edbca102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:52.287189Z",
     "iopub.status.busy": "2022-04-18T00:23:52.286660Z",
     "iopub.status.idle": "2022-04-18T00:23:52.288913Z",
     "shell.execute_reply": "2022-04-18T00:23:52.289304Z"
    },
    "papermill": {
     "duration": 0.034824,
     "end_time": "2022-04-18T00:23:52.289438",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.254614",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"110,0,74.5,117,200.8,98,192.2,101,9.8,7,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"0.02134251780807972\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"00f7d603-cf2d-4040-98f6-d0a1ef9084ca\",\n",
      "    \"inferenceTime\": \"2025-02-20T06:14:51Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(json.loads(capture_file.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b6245",
   "metadata": {
    "papermill": {
     "duration": 0.026948,
     "end_time": "2022-04-18T00:23:52.343438",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.316490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, each inference request is captured in one line in the jsonl file. The line contains both the input and output merged together. In the example, you provided the ContentType as `text/csv` which is reflected in the `observedContentType` value. Also, you expose the encoding that you used to encode the input and output payloads in the capture format with the `encoding` value.\n",
    "\n",
    "To recap, you observed how you can enable capturing the input or output payloads to an endpoint with a new parameter. You have also observed what the captured format looks like in Amazon S3. Next, continue to explore how Amazon SageMaker helps with monitoring the data collected in Amazon S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e43e3",
   "metadata": {
    "papermill": {
     "duration": 0.02743,
     "end_time": "2022-04-18T00:23:52.397993",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.370563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PART B: Model Monitor - Baselining and continuous monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd7dfd",
   "metadata": {
    "papermill": {
     "duration": 0.026767,
     "end_time": "2022-04-18T00:23:52.452009",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.425242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In addition to collecting the data, Amazon SageMaker provides the capability for you to monitor and evaluate the data observed by the endpoints. For this:\n",
    "1. Create a baseline with which you compare the realtime traffic. \n",
    "1. Once a baseline is ready, setup a schedule to continously evaluate and compare against the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e8855",
   "metadata": {
    "papermill": {
     "duration": 0.026868,
     "end_time": "2022-04-18T00:23:52.505930",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.479062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Constraint suggestion with baseline/training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596ed4c",
   "metadata": {
    "papermill": {
     "duration": 0.026955,
     "end_time": "2022-04-18T00:23:52.559834",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.532879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The training dataset with which you trained the model is usually a good baseline dataset. Note that the training dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the training dataset you can ask Amazon SageMaker to suggest a set of baseline `constraints` and generate descriptive `statistics` to explore the data. For this example, upload the training dataset that was used to train the pre-trained model included in this example. If you already have it in Amazon S3, you can directly point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dce35f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:52.618548Z",
     "iopub.status.busy": "2022-04-18T00:23:52.617827Z",
     "iopub.status.idle": "2022-04-18T00:23:52.620899Z",
     "shell.execute_reply": "2022-04-18T00:23:52.621263Z"
    },
    "papermill": {
     "duration": 0.034674,
     "end_time": "2022-04-18T00:23:52.621397",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.586723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/baselining/data\n",
      "Baseline results uri: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/baselining/results\n"
     ]
    }
   ],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db1f8aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:52.697273Z",
     "iopub.status.busy": "2022-04-18T00:23:52.696706Z",
     "iopub.status.idle": "2022-04-18T00:23:52.860994Z",
     "shell.execute_reply": "2022-04-18T00:23:52.860548Z"
    },
    "papermill": {
     "duration": 0.212278,
     "end_time": "2022-04-18T00:23:52.861105",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.648827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:19:15] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:19:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=118354;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=945273;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data_file = open(\"test_data/training-dataset-with-header.csv\", \"rb\")\n",
    "s3_key = os.path.join(baseline_prefix, \"data\", \"training-dataset-with-header.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_key).upload_fileobj(training_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205c9d4",
   "metadata": {
    "papermill": {
     "duration": 0.03685,
     "end_time": "2022-04-18T00:23:52.925824",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.888974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create a baselining job with training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751107f",
   "metadata": {
    "papermill": {
     "duration": 0.028188,
     "end_time": "2022-04-18T00:23:52.997676",
     "exception": false,
     "start_time": "2022-04-18T00:23:52.969488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that you have the training data ready in Amazon S3, start a job to `suggest` constraints. `DefaultModelMonitor.suggest_baseline(..)` starts a `ProcessingJob` using an Amazon SageMaker provided Model Monitor container to generate the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63dc14e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:23:53.066384Z",
     "iopub.status.busy": "2022-04-18T00:23:53.065835Z",
     "iopub.status.idle": "2022-04-18T00:29:46.346123Z",
     "shell.execute_reply": "2022-04-18T00:29:46.346507Z"
    },
    "papermill": {
     "duration": 353.320851,
     "end_time": "2022-04-18T00:29:46.346647",
     "exception": false,
     "start_time": "2022-04-18T00:23:53.025796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:21:37] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:21:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=359926;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=103105;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=964819;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=78800;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=340705;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=780993;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating processing-job with name                                      <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#1575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         baseline-suggestion-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-20-06-51-37-944                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating processing-job with name                                      \u001b]8;id=795909;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=56411;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#1575\u001b\\\u001b[2m1575\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         baseline-suggestion-job-\u001b[1;36m2025\u001b[0m-02-20-06-51-37-944                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........2025-02-20 06:53:33.829950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-02-20 06:53:33.829980: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-20 06:53:35.427039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-02-20 06:53:35.427068: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-02-20 06:53:35.427087: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-254-114.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2025-02-20 06:53:35.427364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-20 06:53:37,018 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:266735799838:processing-job/baseline-suggestion-job-2025-02-20-06-51-37-944', 'ProcessingJobName': 'baseline-suggestion-job-2025-02-20-06-51-37-944', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/baselining/data/training-dataset-with-header.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/baselining/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::266735799838:role/amazonsagemaker-role', 'StoppingCondition': {'MaxRuntimeInSeconds': 360}}\n",
      "2025-02-20 06:53:37,018 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\n",
      "2025-02-20 06:53:37,018 - __main__ - INFO - categorical_drift_method:None\n",
      "2025-02-20 06:53:37,018 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\n",
      "2025-02-20 06:53:37,018 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\n",
      "2025-02-20 06:53:37,019 - bootstrap - INFO - Copy aws jars\n",
      "2025-02-20 06:53:37,066 - bootstrap - INFO - Copy cluster config\n",
      "2025-02-20 06:53:37,066 - bootstrap - INFO - Write runtime cluster config\n",
      "2025-02-20 06:53:37,067 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0'}\n",
      "2025-02-20 06:53:37,075 - bootstrap - INFO - Finished Yarn configuration files setup.\n",
      "2025-02-20 06:53:37,076 - bootstrap - INFO - Starting spark process for master node algo-1\n",
      "2025-02-20 06:53:37,076 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\n",
      "WARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\n",
      "2025-02-20 06:53:37,537 INFO namenode.NameNode: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting NameNode\n",
      "STARTUP_MSG:   host = algo-1/10.2.254.114\n",
      "STARTUP_MSG:   args = [-format, -force]\n",
      "STARTUP_MSG:   version = 3.0.0\n",
      "STARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-\n",
      "nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar\n",
      "STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\n",
      "STARTUP_MSG:   java = 1.8.0_392\n",
      "************************************************************/\n",
      "2025-02-20 06:53:37,545 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
      "2025-02-20 06:53:37,548 INFO namenode.NameNode: createNameNode [-format, -force]\n",
      "Formatting using clusterid: CID-919c5cb9-df9d-44d2-b7c4-6b9a349a2e2d\n",
      "2025-02-20 06:53:38,101 INFO namenode.FSEditLog: Edit logging is async:true\n",
      "2025-02-20 06:53:38,112 INFO namenode.FSNamesystem: KeyProvider: null\n",
      "2025-02-20 06:53:38,113 INFO namenode.FSNamesystem: fsLock is fair: true\n",
      "2025-02-20 06:53:38,115 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
      "2025-02-20 06:53:38,120 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\n",
      "2025-02-20 06:53:38,120 INFO namenode.FSNamesystem: supergroup          = supergroup\n",
      "2025-02-20 06:53:38,120 INFO namenode.FSNamesystem: isPermissionEnabled = true\n",
      "2025-02-20 06:53:38,121 INFO namenode.FSNamesystem: HA Enabled: false\n",
      "2025-02-20 06:53:38,152 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
      "2025-02-20 06:53:38,163 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
      "2025-02-20 06:53:38,163 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
      "2025-02-20 06:53:38,167 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
      "2025-02-20 06:53:38,170 INFO blockmanagement.BlockManager: The block deletion will start around 2025 Feb 20 06:53:38\n",
      "2025-02-20 06:53:38,171 INFO util.GSet: Computing capacity for map BlocksMap\n",
      "2025-02-20 06:53:38,171 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-20 06:53:38,173 INFO util.GSet: 2.0% max memory 3.1 GB = 62.6 MB\n",
      "2025-02-20 06:53:38,173 INFO util.GSet: capacity      = 2^23 = 8388608 entries\n",
      "2025-02-20 06:53:38,209 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\n",
      "2025-02-20 06:53:38,212 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\n",
      "2025-02-20 06:53:38,212 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: defaultReplication         = 3\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: minReplication             = 1\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
      "2025-02-20 06:53:38,213 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
      "2025-02-20 06:53:38,238 INFO util.GSet: Computing capacity for map INodeMap\n",
      "2025-02-20 06:53:38,238 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-20 06:53:38,238 INFO util.GSet: 1.0% max memory 3.1 GB = 31.3 MB\n",
      "2025-02-20 06:53:38,238 INFO util.GSet: capacity      = 2^22 = 4194304 entries\n",
      "2025-02-20 06:53:38,240 INFO namenode.FSDirectory: ACLs enabled? false\n",
      "2025-02-20 06:53:38,240 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\n",
      "2025-02-20 06:53:38,240 INFO namenode.FSDirectory: XAttrs enabled? true\n",
      "2025-02-20 06:53:38,240 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
      "2025-02-20 06:53:38,244 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\n",
      "2025-02-20 06:53:38,248 INFO util.GSet: Computing capacity for map cachedBlocks\n",
      "2025-02-20 06:53:38,248 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-20 06:53:38,248 INFO util.GSet: 0.25% max memory 3.1 GB = 7.8 MB\n",
      "2025-02-20 06:53:38,248 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n",
      "2025-02-20 06:53:38,285 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
      "2025-02-20 06:53:38,285 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
      "2025-02-20 06:53:38,285 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
      "2025-02-20 06:53:38,289 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
      "2025-02-20 06:53:38,289 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
      "2025-02-20 06:53:38,290 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
      "2025-02-20 06:53:38,290 INFO util.GSet: VM type       = 64-bit\n",
      "2025-02-20 06:53:38,291 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 961.8 KB\n",
      "2025-02-20 06:53:38,291 INFO util.GSet: capacity      = 2^17 = 131072 entries\n",
      "2025-02-20 06:53:38,311 INFO namenode.FSImage: Allocated new BlockPoolId: BP-2023503535-10.2.254.114-1740034418305\n",
      "2025-02-20 06:53:38,322 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\n",
      "2025-02-20 06:53:38,329 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\n",
      "2025-02-20 06:53:38,411 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\n",
      "2025-02-20 06:53:38,421 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
      "2025-02-20 06:53:38,425 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
      "/************************************************************\n",
      "SHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.254.114\n",
      "************************************************************/\n",
      "2025-02-20 06:53:38,436 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\n",
      "2025-02-20 06:53:40,496 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\n",
      "2025-02-20 06:53:40,496 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\n",
      "2025-02-20 06:53:42,560 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\n",
      "2025-02-20 06:53:42,561 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "WARNING: /var/log/yarn/ does not exist. Creating.\n",
      "2025-02-20 06:53:44,639 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\n",
      "2025-02-20 06:53:44,640 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2025-02-20 06:53:46,720 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\n",
      "2025-02-20 06:53:46,721 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\n",
      "WARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\n",
      "2025-02-20 06:53:48,797 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\n",
      "2025-02-20 06:53:48,798 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\n",
      "2025-02-20 06:53:58,805 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\n",
      "2025-02-20 06:54:00,511 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2025-02-20 06:54:00,950 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\n",
      "2025-02-20 06:54:00,990 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\n",
      "2025-02-20 06:54:01,000 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\n",
      "2025-02-20 06:54:01,524 INFO spark.SparkContext: Running Spark version 3.3.0\n",
      "2025-02-20 06:54:01,548 INFO resource.ResourceUtils: ==============================================================\n",
      "2025-02-20 06:54:01,549 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\n",
      "2025-02-20 06:54:01,549 INFO resource.ResourceUtils: ==============================================================\n",
      "2025-02-20 06:54:01,550 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\n",
      "2025-02-20 06:54:01,575 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11507, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "2025-02-20 06:54:01,599 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\n",
      "2025-02-20 06:54:01,601 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\n",
      "2025-02-20 06:54:01,651 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2025-02-20 06:54:01,652 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2025-02-20 06:54:01,652 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2025-02-20 06:54:01,652 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2025-02-20 06:54:01,653 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2025-02-20 06:54:02,017 INFO util.Utils: Successfully started service 'sparkDriver' on port 34265.\n",
      "2025-02-20 06:54:02,044 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "2025-02-20 06:54:02,081 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "2025-02-20 06:54:02,109 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2025-02-20 06:54:02,109 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "2025-02-20 06:54:02,154 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "2025-02-20 06:54:02,183 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-4a7b2217-6f44-495b-b643-01fa218c780c\n",
      "2025-02-20 06:54:02,206 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\n",
      "2025-02-20 06:54:02,257 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "2025-02-20 06:54:02,303 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.254.114:34265/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1740034441519\n",
      "2025-02-20 06:54:02,793 INFO client.RMProxy: Connecting to ResourceManager at /10.2.254.114:8032\n",
      "2025-02-20 06:54:03,507 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-02-20 06:54:03,507 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-02-20 06:54:03,513 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15692 MB per container)\n",
      "2025-02-20 06:54:03,514 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
      "2025-02-20 06:54:03,514 INFO yarn.Client: Setting up container launch context for our AM\n",
      "2025-02-20 06:54:03,514 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "2025-02-20 06:54:03,520 INFO yarn.Client: Preparing resources for our AM container\n",
      "2025-02-20 06:54:03,598 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2025-02-20 06:54:10,213 INFO yarn.Client: Uploading resource file:/tmp/spark-4037aa19-3ff0-4a5d-8d4e-97888931a648/__spark_libs__1880774760339909495.zip -> hdfs://10.2.254.114/user/root/.sparkStaging/application_1740034424135_0001/__spark_libs__1880774760339909495.zip\n",
      "2025-02-20 06:54:11,360 INFO yarn.Client: Uploading resource file:/tmp/spark-4037aa19-3ff0-4a5d-8d4e-97888931a648/__spark_conf__5930645376308025018.zip -> hdfs://10.2.254.114/user/root/.sparkStaging/application_1740034424135_0001/__spark_conf__.zip\n",
      "2025-02-20 06:54:11,823 INFO spark.SecurityManager: Changing view acls to: root\n",
      "2025-02-20 06:54:11,824 INFO spark.SecurityManager: Changing modify acls to: root\n",
      "2025-02-20 06:54:11,824 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "2025-02-20 06:54:11,824 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "2025-02-20 06:54:11,824 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2025-02-20 06:54:11,849 INFO yarn.Client: Submitting application application_1740034424135_0001 to ResourceManager\n",
      "2025-02-20 06:54:12,042 INFO impl.YarnClientImpl: Submitted application application_1740034424135_0001\n",
      "2025-02-20 06:54:13,046 INFO yarn.Client: Application report for application_1740034424135_0001 (state: ACCEPTED)\n",
      "2025-02-20 06:54:13,050 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
      "#011 ApplicationMaster host: N/A\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1740034451945\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1740034424135_0001/\n",
      "#011 user: root\n",
      "2025-02-20 06:54:14,057 INFO yarn.Client: Application report for application_1740034424135_0001 (state: ACCEPTED)\n",
      "2025-02-20 06:54:15,060 INFO yarn.Client: Application report for application_1740034424135_0001 (state: ACCEPTED)\n",
      "2025-02-20 06:54:16,063 INFO yarn.Client: Application report for application_1740034424135_0001 (state: ACCEPTED)\n",
      "2025-02-20 06:54:17,027 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1740034424135_0001), /proxy/application_1740034424135_0001\n",
      "2025-02-20 06:54:17,071 INFO yarn.Client: Application report for application_1740034424135_0001 (state: RUNNING)\n",
      "2025-02-20 06:54:17,071 INFO yarn.Client: \n",
      "#011 client token: N/A\n",
      "#011 diagnostics: N/A\n",
      "#011 ApplicationMaster host: 10.2.254.114\n",
      "#011 ApplicationMaster RPC port: -1\n",
      "#011 queue: default\n",
      "#011 start time: 1740034451945\n",
      "#011 final status: UNDEFINED\n",
      "#011 tracking URL: http://algo-1:8088/proxy/application_1740034424135_0001/\n",
      "#011 user: root\n",
      "2025-02-20 06:54:17,073 INFO cluster.YarnClientSchedulerBackend: Application application_1740034424135_0001 has started running.\n",
      "2025-02-20 06:54:17,088 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38645.\n",
      "2025-02-20 06:54:17,088 INFO netty.NettyBlockTransferService: Server created on 10.2.254.114:38645\n",
      "2025-02-20 06:54:17,091 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2025-02-20 06:54:17,101 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.2.254.114, 38645, None)\n",
      "2025-02-20 06:54:17,105 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.2.254.114:38645 with 1458.6 MiB RAM, BlockManagerId(driver, 10.2.254.114, 38645, None)\n",
      "2025-02-20 06:54:17,108 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.2.254.114, 38645, None)\n",
      "2025-02-20 06:54:17,109 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.2.254.114, 38645, None)\n",
      "2025-02-20 06:54:17,257 INFO util.log: Logging initialized @18195ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "2025-02-20 06:54:18,390 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
      "2025-02-20 06:54:21,931 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.254.114:38120) with ID 1,  ResourceProfileId 0\n",
      "2025-02-20 06:54:22,159 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:42061 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 42061, None)\n",
      "2025-02-20 06:54:32,717 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\n",
      "2025-02-20 06:54:32,918 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\n",
      "2025-02-20 06:54:32,970 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "2025-02-20 06:54:32,975 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\n",
      "2025-02-20 06:54:34,019 INFO datasources.InMemoryFileIndex: It took 40 ms to list leaf files for 1 paths.\n",
      "2025-02-20 06:54:34,200 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\n",
      "2025-02-20 06:54:34,510 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\n",
      "2025-02-20 06:54:34,516 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.2.254.114:38645 (size: 39.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:34,522 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\n",
      "2025-02-20 06:54:34,949 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2025-02-20 06:54:34,952 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2025-02-20 06:54:34,955 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 375873\n",
      "2025-02-20 06:54:35,005 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\n",
      "2025-02-20 06:54:35,025 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\n",
      "2025-02-20 06:54:35,025 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\n",
      "2025-02-20 06:54:35,025 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:35,027 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:35,040 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\n",
      "2025-02-20 06:54:35,095 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:54:35,102 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:54:35,103 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.2.254.114:38645 (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:35,105 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:35,119 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:35,120 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:35,170 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:35,427 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:42061 (size: 4.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:36,264 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:42061 (size: 39.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:36,577 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1429 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:36,579 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:36,587 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.516 s\n",
      "2025-02-20 06:54:36,591 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:36,591 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\n",
      "2025-02-20 06:54:36,593 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.588057 s\n",
      "2025-02-20 06:54:36,776 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.2.254.114:38645 in memory (size: 4.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:36,779 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:42061 in memory (size: 4.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:36,817 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.2.254.114:38645 in memory (size: 39.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:36,822 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:42061 in memory (size: 39.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:39,006 INFO datasources.FileSourceStrategy: Pushed Filters: \n",
      "2025-02-20 06:54:39,008 INFO datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "2025-02-20 06:54:39,012 INFO datasources.FileSourceStrategy: Output Data Schema: struct<Churn: string, Account Length: string, VMail Message: string, Day Mins: string, Day Calls: string ... 68 more fields>\n",
      "2025-02-20 06:54:39,056 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "2025-02-20 06:54:39,253 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1458.2 MiB)\n",
      "2025-02-20 06:54:39,268 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\n",
      "2025-02-20 06:54:39,268 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.2.254.114:38645 (size: 39.1 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:39,270 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\n",
      "2025-02-20 06:54:39,286 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "2025-02-20 06:54:39,332 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\n",
      "2025-02-20 06:54:39,334 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\n",
      "2025-02-20 06:54:39,334 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\n",
      "2025-02-20 06:54:39,334 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:39,337 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:39,346 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\n",
      "2025-02-20 06:54:39,407 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 29.8 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:54:39,409 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:54:39,410 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.2.254.114:38645 (size: 11.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:39,411 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:39,411 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:39,412 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:39,415 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:39,454 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:42061 (size: 11.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:40,248 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:42061 (size: 39.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:40,514 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:42061 (size: 188.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:40,701 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1288 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:40,701 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:40,702 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 1.353 s\n",
      "2025-02-20 06:54:40,703 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:40,703 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\n",
      "2025-02-20 06:54:40,709 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 1.376649 s\n",
      "2025-02-20 06:54:41,216 INFO codegen.CodeGenerator: Code generated in 349.067537 ms\n",
      "2025-02-20 06:54:41,343 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.2.254.114:38645 in memory (size: 11.2 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:54:41,353 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:42061 in memory (size: 11.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:41,945 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\n",
      "2025-02-20 06:54:41,948 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:41,949 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:41,949 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:41,951 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:41,953 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:41,974 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 125.7 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:54:41,977 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.7 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:54:41,978 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.2.254.114:38645 (size: 37.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:41,979 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:41,981 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:41,981 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:41,988 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:42,014 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:42061 (size: 37.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:42,999 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1013 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:42,999 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:43,002 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.045 s\n",
      "2025-02-20 06:54:43,002 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:43,005 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:43,006 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:43,006 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:43,099 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:43,102 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:43,102 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:43,102 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "2025-02-20 06:54:43,102 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:43,103 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:43,117 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 178.5 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:43,120 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:43,120 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:43,121 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:43,121 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:43,121 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:43,125 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:43,142 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:43,192 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:43,627 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 503 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:43,627 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:43,629 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.519 s\n",
      "2025-02-20 06:54:43,629 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:43,629 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\n",
      "2025-02-20 06:54:43,631 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.531624 s\n",
      "2025-02-20 06:54:43,676 INFO codegen.CodeGenerator: Code generated in 34.692481 ms\n",
      "2025-02-20 06:54:44,009 INFO codegen.CodeGenerator: Code generated in 47.354025 ms\n",
      "2025-02-20 06:54:44,149 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:44,151 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:44,152 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:44,152 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:44,153 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:44,154 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:44,200 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 49.2 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:44,203 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:44,204 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.2.254.114:38645 (size: 19.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:44,205 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:44,205 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:44,206 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:44,208 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:44,225 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:42061 (size: 19.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:44,739 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 532 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:44,739 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:44,740 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.583 s\n",
      "2025-02-20 06:54:44,742 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:44,742 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\n",
      "2025-02-20 06:54:44,743 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.593116 s\n",
      "2025-02-20 06:54:45,317 INFO codegen.CodeGenerator: Code generated in 98.577766 ms\n",
      "2025-02-20 06:54:45,325 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\n",
      "2025-02-20 06:54:45,326 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:45,326 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:45,326 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:45,327 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:45,328 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:45,333 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 87.0 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:45,335 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:45,336 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.2.254.114:38645 (size: 27.5 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:45,337 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:45,338 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:45,338 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:45,339 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:45,355 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:42061 (size: 27.5 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:45,451 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 112 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:45,451 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:45,454 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.124 s\n",
      "2025-02-20 06:54:45,454 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:45,454 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:45,454 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:45,454 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:45,641 INFO codegen.CodeGenerator: Code generated in 87.628044 ms\n",
      "2025-02-20 06:54:45,652 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:45,654 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:45,654 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:45,654 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "2025-02-20 06:54:45,654 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:45,655 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:45,658 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 67.4 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:45,660 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:45,661 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:45,661 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:45,662 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:45,662 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:45,663 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:45,677 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:45,681 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:45,742 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 79 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:45,742 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:45,743 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.087 s\n",
      "2025-02-20 06:54:45,743 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:45,743 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\n",
      "2025-02-20 06:54:45,744 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.091115 s\n",
      "2025-02-20 06:54:45,804 INFO codegen.CodeGenerator: Code generated in 40.105161 ms\n",
      "2025-02-20 06:54:45,960 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:45,964 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\n",
      "2025-02-20 06:54:45,965 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:45,965 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:45,965 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\n",
      "2025-02-20 06:54:45,966 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\n",
      "2025-02-20 06:54:45,969 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:45,979 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 41.8 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:45,981 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:45,982 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.2.254.114:38645 (size: 17.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:45,983 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:45,984 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:45,984 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:45,986 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:46,000 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:42061 (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:47,304 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1319 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:47,305 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:47,305 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.335 s\n",
      "2025-02-20 06:54:47,306 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:47,307 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:47,308 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\n",
      "2025-02-20 06:54:47,308 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:47,309 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:47,311 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:47,314 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:47,315 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:47,319 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:47,321 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:47,327 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:47,330 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:47,343 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:47,349 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:47,418 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 88 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:47,418 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:47,418 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.108 s\n",
      "2025-02-20 06:54:47,419 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:47,419 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\n",
      "2025-02-20 06:54:47,420 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.459451 s\n",
      "2025-02-20 06:54:47,608 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\n",
      "2025-02-20 06:54:47,608 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:47,608 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:47,608 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:47,609 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:47,610 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:47,616 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 94.7 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:47,619 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:47,620 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:47,621 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:47,623 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:47,623 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:47,625 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:47,638 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,001 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 377 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:48,001 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:48,002 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.391 s\n",
      "2025-02-20 06:54:48,005 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:48,006 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:48,006 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:48,006 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:48,059 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:48,061 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:48,061 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:48,061 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\n",
      "2025-02-20 06:54:48,061 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:48,062 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:48,071 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 179.5 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:48,099 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:48,100 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.2.254.114:38645 (size: 49.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:48,101 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:48,101 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:48,102 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:48,104 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:48,110 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:42061 in memory (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,114 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.2.254.114:38645 in memory (size: 17.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:48,129 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:42061 (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,146 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.2.254.114:38645 in memory (size: 19.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:48,150 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:42061 in memory (size: 19.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,150 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:48,184 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.2.254.114:38645 in memory (size: 27.5 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:48,186 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:42061 in memory (size: 27.5 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,193 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:48,198 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,223 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,227 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,251 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,263 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 159 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:48,263 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:48,267 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.204 s\n",
      "2025-02-20 06:54:48,268 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:48,268 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\n",
      "2025-02-20 06:54:48,268 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.208815 s\n",
      "2025-02-20 06:54:48,271 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,347 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:42061 in memory (size: 37.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,374 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.2.254.114:38645 in memory (size: 37.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,382 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,385 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,398 INFO codegen.CodeGenerator: Code generated in 23.028358 ms\n",
      "2025-02-20 06:54:48,430 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:48,431 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:48,431 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:48,432 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:48,432 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:48,434 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:48,443 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 49.3 KiB, free 1457.9 MiB)\n",
      "2025-02-20 06:54:48,445 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.9 MiB)\n",
      "2025-02-20 06:54:48,446 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,447 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:48,447 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:48,447 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:48,449 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:48,463 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,596 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 147 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:48,596 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:48,598 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.163 s\n",
      "2025-02-20 06:54:48,598 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:48,598 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\n",
      "2025-02-20 06:54:48,599 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.168943 s\n",
      "2025-02-20 06:54:48,806 INFO codegen.CodeGenerator: Code generated in 54.457556 ms\n",
      "2025-02-20 06:54:48,813 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\n",
      "2025-02-20 06:54:48,814 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:48,814 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:48,814 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:48,815 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:48,815 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:48,818 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 86.1 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:48,820 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 27.0 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:48,821 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.2.254.114:38645 (size: 27.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:48,821 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:48,822 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:48,822 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:48,823 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:48,836 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:42061 (size: 27.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:48,915 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 92 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:48,915 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:48,916 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.100 s\n",
      "2025-02-20 06:54:48,916 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:48,916 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:48,916 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:48,916 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:49,018 INFO codegen.CodeGenerator: Code generated in 55.472083 ms\n",
      "2025-02-20 06:54:49,029 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:49,030 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:49,030 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:49,030 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "2025-02-20 06:54:49,030 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:49,030 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:49,032 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.8 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:49,034 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:49,034 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.2.254.114:38645 (size: 19.7 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:49,035 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:49,035 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:49,035 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:49,036 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:49,052 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:42061 (size: 19.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:49,057 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:49,114 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 78 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:49,114 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:49,115 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.084 s\n",
      "2025-02-20 06:54:49,116 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:49,116 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\n",
      "2025-02-20 06:54:49,117 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.088014 s\n",
      "2025-02-20 06:54:49,200 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:49,202 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\n",
      "2025-02-20 06:54:49,202 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:49,202 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:49,202 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "2025-02-20 06:54:49,203 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "2025-02-20 06:54:49,203 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:49,211 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 41.8 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:49,213 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:49,213 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:49,214 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:49,214 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:49,214 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:49,215 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:49,226 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:49,290 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 75 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:49,290 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:49,291 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.086 s\n",
      "2025-02-20 06:54:49,291 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:49,291 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:49,291 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\n",
      "2025-02-20 06:54:49,291 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:49,292 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:49,294 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:49,295 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:49,295 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:49,296 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:49,296 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:49,296 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:49,298 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:49,308 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:49,315 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:49,348 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 50 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:49,348 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:49,349 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.056 s\n",
      "2025-02-20 06:54:49,354 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:49,354 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\n",
      "2025-02-20 06:54:49,354 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.153915 s\n",
      "2025-02-20 06:54:49,504 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\n",
      "2025-02-20 06:54:49,504 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:49,504 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:49,504 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:49,504 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:49,506 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:49,510 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 94.7 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:49,512 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:49,513 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:49,513 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:49,514 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:49,514 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:49,515 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:49,523 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:49,733 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 218 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:49,734 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:49,735 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.227 s\n",
      "2025-02-20 06:54:49,735 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:49,735 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:49,735 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:49,735 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:49,791 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:49,793 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:49,795 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:49,795 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\n",
      "2025-02-20 06:54:49,795 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:49,796 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:49,807 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 179.6 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:49,816 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:49,817 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.2.254.114:38645 (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:49,817 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:49,818 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:49,819 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:49,820 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:49,832 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:42061 (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:49,854 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:49,962 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 142 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:49,963 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:49,964 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.166 s\n",
      "2025-02-20 06:54:49,966 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:49,966 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\n",
      "2025-02-20 06:54:49,967 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.174925 s\n",
      "2025-02-20 06:54:50,113 INFO codegen.CodeGenerator: Code generated in 22.960757 ms\n",
      "2025-02-20 06:54:50,146 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:50,148 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:50,148 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:50,149 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:50,149 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:50,150 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:50,164 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 48.9 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:50,168 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:50,169 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:50,171 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:50,171 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:50,171 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:50,173 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:50,198 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:50,310 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 137 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:50,310 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:50,311 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.160 s\n",
      "2025-02-20 06:54:50,312 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:50,313 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\n",
      "2025-02-20 06:54:50,313 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.166780 s\n",
      "2025-02-20 06:54:50,556 INFO codegen.CodeGenerator: Code generated in 59.161887 ms\n",
      "2025-02-20 06:54:50,566 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\n",
      "2025-02-20 06:54:50,566 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:50,566 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:50,566 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:50,566 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:50,567 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:50,571 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 87.4 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:50,573 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:50,573 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:50,574 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:50,576 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:50,576 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:50,578 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:50,593 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:50,744 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 166 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:50,744 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:50,745 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.177 s\n",
      "2025-02-20 06:54:50,747 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:50,747 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:50,747 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:50,747 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:50,914 INFO codegen.CodeGenerator: Code generated in 86.878811 ms\n",
      "2025-02-20 06:54:50,937 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:50,938 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:50,939 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:50,940 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\n",
      "2025-02-20 06:54:50,940 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:50,940 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:50,942 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 67.7 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:50,944 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:50,944 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:50,945 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:50,946 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:50,949 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:50,951 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:50,963 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:50,968 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:51,053 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 103 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:51,053 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:51,055 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.114 s\n",
      "2025-02-20 06:54:51,056 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:51,056 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\n",
      "2025-02-20 06:54:51,056 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.118356 s\n",
      "2025-02-20 06:54:51,178 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:51,179 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\n",
      "2025-02-20 06:54:51,180 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:51,180 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:51,180 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\n",
      "2025-02-20 06:54:51,181 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\n",
      "2025-02-20 06:54:51,184 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:51,190 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 41.8 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:51,197 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:51,198 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,200 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:51,203 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:51,203 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:51,205 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:51,218 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,267 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 62 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:51,267 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.083 s\n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:51,268 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:51,270 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:51,274 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:51,275 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,275 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:51,276 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:51,276 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:51,277 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:51,290 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,293 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:51,302 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:51,302 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:51,303 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.034 s\n",
      "2025-02-20 06:54:51,303 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:51,303 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\n",
      "2025-02-20 06:54:51,303 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.125090 s\n",
      "2025-02-20 06:54:51,486 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\n",
      "2025-02-20 06:54:51,486 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:51,486 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:51,487 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:51,487 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:51,488 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:51,527 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 94.7 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:51,543 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:51,545 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:51,547 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:51,550 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:51,550 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:51,551 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,553 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:51,562 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,587 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,608 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,614 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,629 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,636 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,653 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,657 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,676 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:42061 in memory (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,694 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.2.254.114:38645 in memory (size: 49.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,714 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,718 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,733 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 180 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:51,733 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:51,734 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.244 s\n",
      "2025-02-20 06:54:51,735 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:51,735 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:51,736 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:51,736 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:51,739 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.2.254.114:38645 in memory (size: 27.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:51,758 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:42061 in memory (size: 27.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,783 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:51,784 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:51,785 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:51,785 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\n",
      "2025-02-20 06:54:51,785 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:51,786 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:51,793 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,801 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:51,804 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 179.5 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:51,806 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:51,807 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:51,808 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:51,808 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:51,808 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:51,811 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:51,824 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,840 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:51,845 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.2.254.114:38645 in memory (size: 49.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:51,847 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:42061 in memory (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,855 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,857 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:51,875 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,882 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:51,892 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,907 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:51,919 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.2.254.114:38645 in memory (size: 19.7 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:51,923 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:42061 in memory (size: 19.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:51,936 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 125 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:51,936 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:51,938 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.150 s\n",
      "2025-02-20 06:54:51,938 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:51,938 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\n",
      "2025-02-20 06:54:51,938 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.155225 s\n",
      "2025-02-20 06:54:52,037 INFO codegen.CodeGenerator: Code generated in 17.114667 ms\n",
      "2025-02-20 06:54:52,070 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:52,072 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:52,072 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:52,072 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:52,073 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:52,074 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:52,084 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 48.9 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:52,085 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:52,086 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:52,086 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,087 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,087 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,089 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,099 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:52,181 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 93 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:52,181 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:52,182 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.107 s\n",
      "2025-02-20 06:54:52,182 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:52,182 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\n",
      "2025-02-20 06:54:52,183 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 0.111630 s\n",
      "2025-02-20 06:54:52,390 INFO codegen.CodeGenerator: Code generated in 32.923002 ms\n",
      "2025-02-20 06:54:52,396 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\n",
      "2025-02-20 06:54:52,396 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:52,396 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:52,396 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:52,396 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:52,397 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:52,401 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 87.4 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:52,403 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:52,404 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:52,405 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,405 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,405 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,407 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,419 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:52,508 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 101 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:52,508 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:52,509 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.111 s\n",
      "2025-02-20 06:54:52,509 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:52,509 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:52,509 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:52,510 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:52,627 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:52,628 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:52,628 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:52,628 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\n",
      "2025-02-20 06:54:52,628 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:52,628 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:52,630 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 67.7 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:52,631 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:52,632 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:52,632 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,632 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,632 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,634 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,647 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:52,653 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:52,665 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 32 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:52,666 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:52,666 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.037 s\n",
      "2025-02-20 06:54:52,666 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:52,666 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\n",
      "2025-02-20 06:54:52,667 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.039870 s\n",
      "2025-02-20 06:54:52,729 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:52,730 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\n",
      "2025-02-20 06:54:52,731 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:52,731 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:52,731 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\n",
      "2025-02-20 06:54:52,731 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\n",
      "2025-02-20 06:54:52,732 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:52,737 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 41.8 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:52,738 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:52,739 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:52,739 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,740 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,740 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,741 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,749 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:52,786 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 45 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:52,786 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:52,787 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.055 s\n",
      "2025-02-20 06:54:52,787 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:52,787 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:52,787 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\n",
      "2025-02-20 06:54:52,787 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:52,788 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:52,791 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:52,796 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:52,796 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:52,797 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,797 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,798 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,799 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,810 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:52,813 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:52,822 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 24 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:52,822 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:52,823 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\n",
      "2025-02-20 06:54:52,823 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:52,823 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\n",
      "2025-02-20 06:54:52,825 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.095875 s\n",
      "2025-02-20 06:54:52,967 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\n",
      "2025-02-20 06:54:52,967 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:52,967 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:52,967 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:52,968 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:52,969 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:52,971 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 94.7 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:52,973 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:52,973 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:52,974 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:52,974 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:52,975 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:52,978 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:52,988 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:53,081 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 104 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:53,081 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:53,082 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.113 s\n",
      "2025-02-20 06:54:53,082 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:53,082 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:53,082 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:53,082 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:53,107 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:53,108 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:53,108 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:53,108 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\n",
      "2025-02-20 06:54:53,108 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:53,108 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:53,115 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 179.5 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:53,119 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:53,119 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:53,120 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:53,120 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:53,120 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:53,122 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:53,132 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:53,145 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:53,240 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 119 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:53,240 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:53,241 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.132 s\n",
      "2025-02-20 06:54:53,242 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:53,242 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\n",
      "2025-02-20 06:54:53,243 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.136190 s\n",
      "2025-02-20 06:54:53,393 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:53,394 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:53,395 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:53,395 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:53,395 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:53,395 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:53,402 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 48.9 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:53,403 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:53,403 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:53,404 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:53,404 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:53,405 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:53,406 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:53,425 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:53,475 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 69 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:53,476 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:53,476 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.080 s\n",
      "2025-02-20 06:54:53,478 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:53,478 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\n",
      "2025-02-20 06:54:53,479 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.084893 s\n",
      "2025-02-20 06:54:53,677 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\n",
      "2025-02-20 06:54:53,677 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:53,677 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:53,677 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:53,678 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:53,678 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:53,682 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 87.4 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:53,684 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:53,684 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.2.254.114:38645 (size: 27.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:53,684 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:53,685 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:53,685 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:53,686 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:53,696 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:42061 (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:53,717 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:53,717 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:53,718 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.039 s\n",
      "2025-02-20 06:54:53,718 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:53,718 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:53,718 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:53,719 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:53,806 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:53,807 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:53,809 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:53,809 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\n",
      "2025-02-20 06:54:53,809 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:53,810 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:53,811 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 67.7 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:53,814 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:53,815 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:53,816 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:53,816 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:53,816 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:53,819 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:53,834 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:53,844 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:53,856 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 38 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:53,856 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:53,857 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.047 s\n",
      "2025-02-20 06:54:53,857 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:53,857 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\n",
      "2025-02-20 06:54:53,857 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.050629 s\n",
      "2025-02-20 06:54:53,916 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:53,917 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\n",
      "2025-02-20 06:54:53,917 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:53,917 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:53,917 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n",
      "2025-02-20 06:54:53,917 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\n",
      "2025-02-20 06:54:53,918 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:53,928 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 41.8 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:53,931 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:53,932 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:53,932 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:53,933 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:53,933 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:53,935 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:53,948 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,009 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 75 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:54,010 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:54,011 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.092 s\n",
      "2025-02-20 06:54:54,011 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:54,012 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:54,012 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\n",
      "2025-02-20 06:54:54,012 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:54,013 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:54,014 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:54,018 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:54,019 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,020 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:54,021 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:54,021 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:54,022 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:54,039 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,047 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:54,064 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 42 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:54,064 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:54,064 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.051 s\n",
      "2025-02-20 06:54:54,065 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:54,065 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\n",
      "2025-02-20 06:54:54,065 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.149409 s\n",
      "2025-02-20 06:54:54,203 INFO scheduler.DAGScheduler: Registering RDD 191 (collect at AnalysisRunner.scala:326) as input to shuffle 15\n",
      "2025-02-20 06:54:54,203 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:54,203 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:54,204 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:54,204 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:54,205 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:54,209 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 94.7 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:54,210 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:54,211 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,211 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:54,212 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:54,212 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:54,213 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:54,228 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,362 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 149 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:54,362 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:54,363 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326) finished in 0.158 s\n",
      "2025-02-20 06:54:54,365 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:54,365 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:54,365 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:54,365 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:54,410 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:54,411 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:54,412 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:54,412 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "2025-02-20 06:54:54,412 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:54,413 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:54,420 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 179.5 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:54,421 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:54,422 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.2.254.114:38645 (size: 49.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,422 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:54,423 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:54,423 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:54,424 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:54,434 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:42061 (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,444 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:54,547 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 123 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:54,547 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:54,550 INFO scheduler.DAGScheduler: ResultStage 49 (collect at AnalysisRunner.scala:326) finished in 0.134 s\n",
      "2025-02-20 06:54:54,550 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:54,550 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\n",
      "2025-02-20 06:54:54,551 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.140747 s\n",
      "2025-02-20 06:54:54,728 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,728 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,737 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,738 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,741 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:54,746 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,751 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,751 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,758 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,759 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,762 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,762 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,764 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:54,765 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.2.254.114:38645 in memory (size: 27.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,766 INFO scheduler.DAGScheduler: Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:54,766 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:54,766 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:54,767 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:42061 in memory (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,767 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:54,767 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:54,771 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,772 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,778 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 48.9 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:54,780 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,780 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:54,781 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,781 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:54,782 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:54,785 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:54,785 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:54,787 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 39) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:54,788 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,793 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:54,796 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,797 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,812 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:54,823 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:54,826 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,832 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:54,834 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,844 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:54,847 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,850 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:54,853 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,860 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.2.254.114:38645 in memory (size: 49.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:54,868 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:42061 in memory (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:54,884 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 39) in 98 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:54,891 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:54,891 INFO scheduler.DAGScheduler: ResultStage 50 (treeReduce at KLLRunner.scala:107) finished in 0.122 s\n",
      "2025-02-20 06:54:54,892 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:54,892 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\n",
      "2025-02-20 06:54:54,893 INFO scheduler.DAGScheduler: Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.128074 s\n",
      "2025-02-20 06:54:55,058 INFO scheduler.DAGScheduler: Registering RDD 209 (collect at AnalysisRunner.scala:326) as input to shuffle 16\n",
      "2025-02-20 06:54:55,058 INFO scheduler.DAGScheduler: Got map stage job 35 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:55,059 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:55,059 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:55,059 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:55,059 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:55,062 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 87.4 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:54:55,064 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:54:55,065 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.2.254.114:38645 (size: 27.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:55,065 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,066 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,066 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,067 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 40) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,083 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:42061 (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,122 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 40) in 55 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,123 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,123 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326) finished in 0.063 s\n",
      "2025-02-20 06:54:55,123 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:55,123 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:55,123 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:55,123 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:55,197 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:55,198 INFO scheduler.DAGScheduler: Got job 36 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:55,198 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:55,198 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\n",
      "2025-02-20 06:54:55,198 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:55,199 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:55,201 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 67.7 KiB, free 1457.9 MiB)\n",
      "2025-02-20 06:54:55,204 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.9 MiB)\n",
      "2025-02-20 06:54:55,204 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:55,205 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,205 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,205 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,206 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 41) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,218 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,221 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:55,229 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 41) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,229 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,230 INFO scheduler.DAGScheduler: ResultStage 53 (collect at AnalysisRunner.scala:326) finished in 0.030 s\n",
      "2025-02-20 06:54:55,230 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:55,230 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\n",
      "2025-02-20 06:54:55,231 INFO scheduler.DAGScheduler: Job 36 finished: collect at AnalysisRunner.scala:326, took 0.033174 s\n",
      "2025-02-20 06:54:55,276 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:55,276 INFO scheduler.DAGScheduler: Registering RDD 220 (countByKey at ColumnProfiler.scala:592) as input to shuffle 17\n",
      "2025-02-20 06:54:55,276 INFO scheduler.DAGScheduler: Got job 37 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:55,276 INFO scheduler.DAGScheduler: Final stage: ResultStage 55 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:55,277 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n",
      "2025-02-20 06:54:55,277 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n",
      "2025-02-20 06:54:55,277 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:55,282 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 41.8 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:55,283 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:55,283 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:55,283 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,284 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,284 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,285 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 42) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,293 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,328 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 42) in 43 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,328 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,328 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (countByKey at ColumnProfiler.scala:592) finished in 0.050 s\n",
      "2025-02-20 06:54:55,329 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:55,329 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:55,329 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 55)\n",
      "2025-02-20 06:54:55,329 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:55,330 INFO scheduler.DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:55,331 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:55,333 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:55,335 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:55,335 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,335 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,335 INFO cluster.YarnScheduler: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,336 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,344 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,347 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:55,356 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,356 INFO cluster.YarnScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,357 INFO scheduler.DAGScheduler: ResultStage 55 (countByKey at ColumnProfiler.scala:592) finished in 0.027 s\n",
      "2025-02-20 06:54:55,357 INFO scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:55,357 INFO cluster.YarnScheduler: Killing all running tasks in stage 55: Stage finished\n",
      "2025-02-20 06:54:55,358 INFO scheduler.DAGScheduler: Job 37 finished: countByKey at ColumnProfiler.scala:592, took 0.081906 s\n",
      "2025-02-20 06:54:55,483 INFO scheduler.DAGScheduler: Registering RDD 226 (collect at AnalysisRunner.scala:326) as input to shuffle 18\n",
      "2025-02-20 06:54:55,483 INFO scheduler.DAGScheduler: Got map stage job 38 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:55,483 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:55,483 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:55,484 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:55,484 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:55,487 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 94.7 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:55,488 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:55,489 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:55,489 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,489 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,490 INFO cluster.YarnScheduler: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,491 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,504 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,614 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 124 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,614 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,614 INFO scheduler.DAGScheduler: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326) finished in 0.129 s\n",
      "2025-02-20 06:54:55,614 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:55,614 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:55,614 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:55,614 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:55,649 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:55,650 INFO scheduler.DAGScheduler: Got job 39 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:55,650 INFO scheduler.DAGScheduler: Final stage: ResultStage 58 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:55,650 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\n",
      "2025-02-20 06:54:55,650 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:55,650 INFO scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:55,656 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 179.5 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:55,658 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 49.1 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:55,659 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.2.254.114:38645 (size: 49.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:55,659 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,660 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,660 INFO cluster.YarnScheduler: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,669 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:42061 (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,677 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:55,763 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 101 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,763 INFO cluster.YarnScheduler: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,764 INFO scheduler.DAGScheduler: ResultStage 58 (collect at AnalysisRunner.scala:326) finished in 0.112 s\n",
      "2025-02-20 06:54:55,764 INFO scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:55,765 INFO cluster.YarnScheduler: Killing all running tasks in stage 58: Stage finished\n",
      "2025-02-20 06:54:55,765 INFO scheduler.DAGScheduler: Job 39 finished: collect at AnalysisRunner.scala:326, took 0.115460 s\n",
      "2025-02-20 06:54:55,871 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:55,871 INFO scheduler.DAGScheduler: Got job 40 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:55,871 INFO scheduler.DAGScheduler: Final stage: ResultStage 59 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:55,871 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:55,872 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:55,872 INFO scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:55,876 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 48.9 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:55,878 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:55,878 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:55,881 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:55,881 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:55,881 INFO cluster.YarnScheduler: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:55,883 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:55,891 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:55,933 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 51 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:55,933 INFO cluster.YarnScheduler: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:55,933 INFO scheduler.DAGScheduler: ResultStage 59 (treeReduce at KLLRunner.scala:107) finished in 0.061 s\n",
      "2025-02-20 06:54:55,934 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:55,934 INFO cluster.YarnScheduler: Killing all running tasks in stage 59: Stage finished\n",
      "2025-02-20 06:54:55,934 INFO scheduler.DAGScheduler: Job 40 finished: treeReduce at KLLRunner.scala:107, took 0.063674 s\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Registering RDD 244 (collect at AnalysisRunner.scala:326) as input to shuffle 19\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Got map stage job 41 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,048 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,052 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 87.4 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:56,053 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:56,054 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:56,054 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,054 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,054 INFO cluster.YarnScheduler: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,055 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 47) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,064 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,078 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 47) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,079 INFO cluster.YarnScheduler: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,080 INFO scheduler.DAGScheduler: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326) finished in 0.031 s\n",
      "2025-02-20 06:54:56,080 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:56,080 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:56,081 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:56,081 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:56,126 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:56,127 INFO scheduler.DAGScheduler: Got job 42 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,128 INFO scheduler.DAGScheduler: Final stage: ResultStage 62 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,128 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "2025-02-20 06:54:56,128 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,128 INFO scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,131 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 67.7 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:56,132 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:56,133 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:56,133 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,133 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,134 INFO cluster.YarnScheduler: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,135 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,144 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,147 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:56,152 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,152 INFO cluster.YarnScheduler: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,153 INFO scheduler.DAGScheduler: ResultStage 62 (collect at AnalysisRunner.scala:326) finished in 0.024 s\n",
      "2025-02-20 06:54:56,153 INFO scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:56,153 INFO cluster.YarnScheduler: Killing all running tasks in stage 62: Stage finished\n",
      "2025-02-20 06:54:56,154 INFO scheduler.DAGScheduler: Job 42 finished: collect at AnalysisRunner.scala:326, took 0.027144 s\n",
      "2025-02-20 06:54:56,201 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:56,202 INFO scheduler.DAGScheduler: Registering RDD 255 (countByKey at ColumnProfiler.scala:592) as input to shuffle 20\n",
      "2025-02-20 06:54:56,203 INFO scheduler.DAGScheduler: Got job 43 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:56,203 INFO scheduler.DAGScheduler: Final stage: ResultStage 64 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:56,203 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\n",
      "2025-02-20 06:54:56,203 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 63)\n",
      "2025-02-20 06:54:56,203 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:56,210 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 41.8 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:56,212 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:56,216 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:56,216 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,217 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,217 INFO cluster.YarnScheduler: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,219 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,231 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,284 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 66 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,284 INFO cluster.YarnScheduler: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,284 INFO scheduler.DAGScheduler: ShuffleMapStage 63 (countByKey at ColumnProfiler.scala:592) finished in 0.080 s\n",
      "2025-02-20 06:54:56,284 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:56,284 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:56,285 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 64)\n",
      "2025-02-20 06:54:56,285 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:56,285 INFO scheduler.DAGScheduler: Submitting ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:56,286 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:56,287 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:56,290 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:56,291 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,291 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,291 INFO cluster.YarnScheduler: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,292 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 50) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,299 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,302 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:56,310 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 50) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,310 INFO cluster.YarnScheduler: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,311 INFO scheduler.DAGScheduler: ResultStage 64 (countByKey at ColumnProfiler.scala:592) finished in 0.026 s\n",
      "2025-02-20 06:54:56,311 INFO scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:56,311 INFO cluster.YarnScheduler: Killing all running tasks in stage 64: Stage finished\n",
      "2025-02-20 06:54:56,311 INFO scheduler.DAGScheduler: Job 43 finished: countByKey at ColumnProfiler.scala:592, took 0.109618 s\n",
      "2025-02-20 06:54:56,392 INFO scheduler.DAGScheduler: Registering RDD 261 (collect at AnalysisRunner.scala:326) as input to shuffle 21\n",
      "2025-02-20 06:54:56,393 INFO scheduler.DAGScheduler: Got map stage job 44 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,393 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,393 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:56,394 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,394 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,398 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 94.7 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:56,399 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:56,400 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:56,400 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,400 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,400 INFO cluster.YarnScheduler: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,401 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 51) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,407 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,513 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 51) in 112 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,513 INFO cluster.YarnScheduler: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,514 INFO scheduler.DAGScheduler: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326) finished in 0.119 s\n",
      "2025-02-20 06:54:56,514 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:56,515 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:56,515 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:56,515 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:56,549 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:56,550 INFO scheduler.DAGScheduler: Got job 45 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,550 INFO scheduler.DAGScheduler: Final stage: ResultStage 67 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,550 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "2025-02-20 06:54:56,550 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,550 INFO scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,556 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 179.5 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:56,558 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:56,558 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:56,559 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,559 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,559 INFO cluster.YarnScheduler: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,560 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 52) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,567 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,577 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:56,653 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 52) in 93 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,654 INFO cluster.YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,654 INFO scheduler.DAGScheduler: ResultStage 67 (collect at AnalysisRunner.scala:326) finished in 0.103 s\n",
      "2025-02-20 06:54:56,654 INFO scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:56,654 INFO cluster.YarnScheduler: Killing all running tasks in stage 67: Stage finished\n",
      "2025-02-20 06:54:56,655 INFO scheduler.DAGScheduler: Job 45 finished: collect at AnalysisRunner.scala:326, took 0.105021 s\n",
      "2025-02-20 06:54:56,734 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:56,735 INFO scheduler.DAGScheduler: Got job 46 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:56,735 INFO scheduler.DAGScheduler: Final stage: ResultStage 68 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:56,735 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:56,735 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,736 INFO scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:56,741 INFO memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 48.9 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:56,742 INFO memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:56,742 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:56,743 INFO spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,743 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,743 INFO cluster.YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,745 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 53) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,751 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,798 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 53) in 54 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,799 INFO cluster.YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,799 INFO scheduler.DAGScheduler: ResultStage 68 (treeReduce at KLLRunner.scala:107) finished in 0.063 s\n",
      "2025-02-20 06:54:56,800 INFO scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:56,800 INFO cluster.YarnScheduler: Killing all running tasks in stage 68: Stage finished\n",
      "2025-02-20 06:54:56,800 INFO scheduler.DAGScheduler: Job 46 finished: treeReduce at KLLRunner.scala:107, took 0.065815 s\n",
      "2025-02-20 06:54:56,892 INFO scheduler.DAGScheduler: Registering RDD 279 (collect at AnalysisRunner.scala:326) as input to shuffle 22\n",
      "2025-02-20 06:54:56,892 INFO scheduler.DAGScheduler: Got map stage job 47 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,893 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,893 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:56,893 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,893 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,898 INFO memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 87.4 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:56,901 INFO memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1456.6 MiB)\n",
      "2025-02-20 06:54:56,902 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.2.254.114:38645 (size: 27.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:56,902 INFO spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,902 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,903 INFO cluster.YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,904 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 54) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,913 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on algo-1:42061 (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,926 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 54) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:56,926 INFO cluster.YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:56,926 INFO scheduler.DAGScheduler: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326) finished in 0.032 s\n",
      "2025-02-20 06:54:56,926 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:56,927 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:56,927 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:56,927 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:56,978 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:56,979 INFO scheduler.DAGScheduler: Got job 48 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:56,979 INFO scheduler.DAGScheduler: Final stage: ResultStage 71 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:56,979 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "2025-02-20 06:54:56,979 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:56,979 INFO scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:56,981 INFO memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 67.7 KiB, free 1456.6 MiB)\n",
      "2025-02-20 06:54:56,982 INFO memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:56,982 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:56,983 INFO spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:56,983 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:56,983 INFO cluster.YarnScheduler: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:56,984 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 55) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:56,994 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:56,997 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:57,005 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 55) in 21 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,005 INFO cluster.YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,006 INFO scheduler.DAGScheduler: ResultStage 71 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2025-02-20 06:54:57,006 INFO scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:57,006 INFO cluster.YarnScheduler: Killing all running tasks in stage 71: Stage finished\n",
      "2025-02-20 06:54:57,014 INFO scheduler.DAGScheduler: Job 48 finished: collect at AnalysisRunner.scala:326, took 0.035534 s\n",
      "2025-02-20 06:54:57,068 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:57,069 INFO scheduler.DAGScheduler: Registering RDD 290 (countByKey at ColumnProfiler.scala:592) as input to shuffle 23\n",
      "2025-02-20 06:54:57,070 INFO scheduler.DAGScheduler: Got job 49 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:57,070 INFO scheduler.DAGScheduler: Final stage: ResultStage 73 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:57,070 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\n",
      "2025-02-20 06:54:57,070 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\n",
      "2025-02-20 06:54:57,070 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:57,077 INFO memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 41.8 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:57,080 INFO memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:57,080 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.2.254.114:38645 (size: 17.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:57,081 INFO spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,081 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,081 INFO cluster.YarnScheduler: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,083 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 56) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,091 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on algo-1:42061 (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,112 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 56) in 29 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,112 INFO cluster.YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,113 INFO scheduler.DAGScheduler: ShuffleMapStage 72 (countByKey at ColumnProfiler.scala:592) finished in 0.042 s\n",
      "2025-02-20 06:54:57,113 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:57,113 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:57,113 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 73)\n",
      "2025-02-20 06:54:57,113 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:57,114 INFO scheduler.DAGScheduler: Submitting ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:57,118 INFO memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 5.1 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:57,124 INFO memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:57,125 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:57,126 INFO spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,126 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,126 INFO cluster.YarnScheduler: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,127 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 57) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,137 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,140 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:57,152 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 57) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,152 INFO cluster.YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,153 INFO scheduler.DAGScheduler: ResultStage 73 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\n",
      "2025-02-20 06:54:57,154 INFO scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:57,154 INFO cluster.YarnScheduler: Killing all running tasks in stage 73: Stage finished\n",
      "2025-02-20 06:54:57,159 INFO scheduler.DAGScheduler: Job 49 finished: countByKey at ColumnProfiler.scala:592, took 0.090228 s\n",
      "2025-02-20 06:54:57,257 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:42061 in memory (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,265 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.2.254.114:38645 in memory (size: 49.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:57,271 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,276 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:57,278 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,283 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:57,288 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:57,289 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,292 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,298 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:57,301 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,305 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:57,315 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:57,316 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,319 INFO scheduler.DAGScheduler: Registering RDD 296 (collect at AnalysisRunner.scala:326) as input to shuffle 24\n",
      "2025-02-20 06:54:57,319 INFO scheduler.DAGScheduler: Got map stage job 50 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:57,319 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:57,320 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:57,321 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:57,321 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:57,322 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,326 INFO memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 94.7 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:54:57,329 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,334 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,340 INFO memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:57,340 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,341 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:57,342 INFO spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,342 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,344 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,344 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,345 INFO cluster.YarnScheduler: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,345 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,346 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,347 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,349 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,352 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,355 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,356 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,357 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,362 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.2.254.114:38645 in memory (size: 17.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,363 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on algo-1:42061 in memory (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,365 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.2.254.114:38645 in memory (size: 27.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,366 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on algo-1:42061 in memory (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,373 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,374 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,376 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,376 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,378 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.2.254.114:38645 in memory (size: 27.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,379 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:42061 in memory (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,384 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,384 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,493 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 146 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,493 INFO cluster.YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,494 INFO scheduler.DAGScheduler: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326) finished in 0.171 s\n",
      "2025-02-20 06:54:57,495 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:57,495 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:57,496 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:57,496 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:57,528 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:57,529 INFO scheduler.DAGScheduler: Got job 51 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:57,529 INFO scheduler.DAGScheduler: Final stage: ResultStage 76 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:57,529 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\n",
      "2025-02-20 06:54:57,529 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:57,530 INFO scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:57,536 INFO memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 179.5 KiB, free 1457.9 MiB)\n",
      "2025-02-20 06:54:57,538 INFO memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 49.1 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:57,538 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.2.254.114:38645 (size: 49.1 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,539 INFO spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,540 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,540 INFO cluster.YarnScheduler: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,541 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 59) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,557 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on algo-1:42061 (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,569 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:57,646 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 59) in 105 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,649 INFO cluster.YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,650 INFO scheduler.DAGScheduler: ResultStage 76 (collect at AnalysisRunner.scala:326) finished in 0.119 s\n",
      "2025-02-20 06:54:57,650 INFO scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:57,651 INFO cluster.YarnScheduler: Killing all running tasks in stage 76: Stage finished\n",
      "2025-02-20 06:54:57,651 INFO scheduler.DAGScheduler: Job 51 finished: collect at AnalysisRunner.scala:326, took 0.122819 s\n",
      "2025-02-20 06:54:57,735 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:57,736 INFO scheduler.DAGScheduler: Got job 52 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:57,736 INFO scheduler.DAGScheduler: Final stage: ResultStage 77 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:57,736 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:57,736 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:57,737 INFO scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:57,742 INFO memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 48.9 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:54:57,743 INFO memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:57,743 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:54:57,743 INFO spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,744 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,744 INFO cluster.YarnScheduler: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,745 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,751 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,790 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 46 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,790 INFO cluster.YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,790 INFO scheduler.DAGScheduler: ResultStage 77 (treeReduce at KLLRunner.scala:107) finished in 0.052 s\n",
      "2025-02-20 06:54:57,790 INFO scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:57,791 INFO cluster.YarnScheduler: Killing all running tasks in stage 77: Stage finished\n",
      "2025-02-20 06:54:57,791 INFO scheduler.DAGScheduler: Job 52 finished: treeReduce at KLLRunner.scala:107, took 0.055899 s\n",
      "2025-02-20 06:54:57,890 INFO scheduler.DAGScheduler: Registering RDD 314 (collect at AnalysisRunner.scala:326) as input to shuffle 25\n",
      "2025-02-20 06:54:57,890 INFO scheduler.DAGScheduler: Got map stage job 53 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:57,890 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:57,890 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:57,890 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:57,891 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:57,893 INFO memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 87.4 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:54:57,895 INFO memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:57,895 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,895 INFO spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,896 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,896 INFO cluster.YarnScheduler: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,897 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 61) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,906 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:57,915 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 61) in 19 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:57,915 INFO cluster.YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:57,916 INFO scheduler.DAGScheduler: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326) finished in 0.023 s\n",
      "2025-02-20 06:54:57,916 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:57,916 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:57,916 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:57,916 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:57,973 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:57,974 INFO scheduler.DAGScheduler: Got job 54 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:57,974 INFO scheduler.DAGScheduler: Final stage: ResultStage 80 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:57,974 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n",
      "2025-02-20 06:54:57,975 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:57,975 INFO scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:57,977 INFO memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 67.7 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:54:57,979 INFO memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:57,980 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.2.254.114:38645 (size: 19.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:57,982 INFO spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:57,982 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:57,983 INFO cluster.YarnScheduler: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:57,984 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 62) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:57,993 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on algo-1:42061 (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:58,007 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:58,013 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 62) in 30 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:58,014 INFO cluster.YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:58,014 INFO scheduler.DAGScheduler: ResultStage 80 (collect at AnalysisRunner.scala:326) finished in 0.038 s\n",
      "2025-02-20 06:54:58,015 INFO scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:58,015 INFO cluster.YarnScheduler: Killing all running tasks in stage 80: Stage finished\n",
      "2025-02-20 06:54:58,015 INFO scheduler.DAGScheduler: Job 54 finished: collect at AnalysisRunner.scala:326, took 0.041998 s\n",
      "2025-02-20 06:54:58,096 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:58,097 INFO scheduler.DAGScheduler: Registering RDD 325 (countByKey at ColumnProfiler.scala:592) as input to shuffle 26\n",
      "2025-02-20 06:54:58,098 INFO scheduler.DAGScheduler: Got job 55 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:58,099 INFO scheduler.DAGScheduler: Final stage: ResultStage 82 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:58,099 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\n",
      "2025-02-20 06:54:58,099 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 81)\n",
      "2025-02-20 06:54:58,100 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:58,105 INFO memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 41.8 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:58,108 INFO memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:58,108 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.2.254.114:38645 (size: 17.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:58,109 INFO spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:58,109 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:58,110 INFO cluster.YarnScheduler: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:58,112 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 63) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:58,119 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on algo-1:42061 (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:58,141 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 63) in 29 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: ShuffleMapStage 81 (countByKey at ColumnProfiler.scala:592) finished in 0.041 s\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 82)\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:58,142 INFO scheduler.DAGScheduler: Submitting ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:58,144 INFO memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:58,145 INFO memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:54:58,145 INFO cluster.YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:58,146 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:58,146 INFO spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:58,147 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:58,147 INFO cluster.YarnScheduler: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:58,148 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 64) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:58,157 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:58,159 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:58,167 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 64) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:58,167 INFO cluster.YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:58,167 INFO scheduler.DAGScheduler: ResultStage 82 (countByKey at ColumnProfiler.scala:592) finished in 0.024 s\n",
      "2025-02-20 06:54:58,167 INFO scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:58,168 INFO cluster.YarnScheduler: Killing all running tasks in stage 82: Stage finished\n",
      "2025-02-20 06:54:58,168 INFO scheduler.DAGScheduler: Job 55 finished: countByKey at ColumnProfiler.scala:592, took 0.071416 s\n",
      "2025-02-20 06:54:58,383 INFO scheduler.DAGScheduler: Registering RDD 331 (collect at AnalysisRunner.scala:326) as input to shuffle 27\n",
      "2025-02-20 06:54:58,383 INFO scheduler.DAGScheduler: Got map stage job 56 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:58,383 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:58,383 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:58,383 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:58,384 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:58,390 INFO memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 94.7 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:58,392 INFO memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:54:58,392 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:54:58,393 INFO spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:58,394 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:58,394 INFO cluster.YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:58,395 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 65) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:58,405 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:58,555 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 65) in 160 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:58,555 INFO cluster.YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:58,556 INFO scheduler.DAGScheduler: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326) finished in 0.170 s\n",
      "2025-02-20 06:54:58,557 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:58,557 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:58,557 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:58,557 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:58,614 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:58,615 INFO scheduler.DAGScheduler: Got job 57 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:58,615 INFO scheduler.DAGScheduler: Final stage: ResultStage 85 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:58,615 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "2025-02-20 06:54:58,615 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:58,615 INFO scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:58,624 INFO memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 179.5 KiB, free 1457.2 MiB)\n",
      "2025-02-20 06:54:58,628 INFO memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:58,629 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:58,630 INFO spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:58,636 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:58,636 INFO cluster.YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:58,637 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 66) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:58,648 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:58,660 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:58,828 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 66) in 191 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:58,828 INFO cluster.YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:58,829 INFO scheduler.DAGScheduler: ResultStage 85 (collect at AnalysisRunner.scala:326) finished in 0.212 s\n",
      "2025-02-20 06:54:58,829 INFO scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:58,829 INFO cluster.YarnScheduler: Killing all running tasks in stage 85: Stage finished\n",
      "2025-02-20 06:54:58,830 INFO scheduler.DAGScheduler: Job 57 finished: collect at AnalysisRunner.scala:326, took 0.215694 s\n",
      "2025-02-20 06:54:58,957 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:58,958 INFO scheduler.DAGScheduler: Got job 58 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:58,958 INFO scheduler.DAGScheduler: Final stage: ResultStage 86 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:58,958 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:58,958 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:58,958 INFO scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:58,963 INFO memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 48.9 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:58,964 INFO memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:54:58,965 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:58,965 INFO spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:58,965 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:58,965 INFO cluster.YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:58,966 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 67) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:58,975 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,012 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 67) in 46 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,012 INFO cluster.YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,013 INFO scheduler.DAGScheduler: ResultStage 86 (treeReduce at KLLRunner.scala:107) finished in 0.054 s\n",
      "2025-02-20 06:54:59,013 INFO scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:59,014 INFO cluster.YarnScheduler: Killing all running tasks in stage 86: Stage finished\n",
      "2025-02-20 06:54:59,014 INFO scheduler.DAGScheduler: Job 58 finished: treeReduce at KLLRunner.scala:107, took 0.056477 s\n",
      "2025-02-20 06:54:59,114 INFO scheduler.DAGScheduler: Registering RDD 349 (collect at AnalysisRunner.scala:326) as input to shuffle 28\n",
      "2025-02-20 06:54:59,114 INFO scheduler.DAGScheduler: Got map stage job 59 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:59,115 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:59,115 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:59,115 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,115 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:59,118 INFO memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 87.4 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:59,119 INFO memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:54:59,120 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:59,120 INFO spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,120 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,120 INFO cluster.YarnScheduler: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,121 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 68) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,131 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,142 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 68) in 21 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,142 INFO cluster.YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,142 INFO scheduler.DAGScheduler: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326) finished in 0.026 s\n",
      "2025-02-20 06:54:59,143 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:59,143 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:59,143 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:59,143 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:59,178 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:59,179 INFO scheduler.DAGScheduler: Got job 60 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:59,179 INFO scheduler.DAGScheduler: Final stage: ResultStage 89 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:59,179 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "2025-02-20 06:54:59,179 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,179 INFO scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:59,181 INFO memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 67.7 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:59,182 INFO memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:54:59,183 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:54:59,183 INFO spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,183 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,183 INFO cluster.YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,184 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 69) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,191 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,195 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:59,202 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 69) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,202 INFO cluster.YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,203 INFO scheduler.DAGScheduler: ResultStage 89 (collect at AnalysisRunner.scala:326) finished in 0.023 s\n",
      "2025-02-20 06:54:59,203 INFO scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:59,203 INFO cluster.YarnScheduler: Killing all running tasks in stage 89: Stage finished\n",
      "2025-02-20 06:54:59,204 INFO scheduler.DAGScheduler: Job 60 finished: collect at AnalysisRunner.scala:326, took 0.025508 s\n",
      "2025-02-20 06:54:59,248 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:54:59,249 INFO scheduler.DAGScheduler: Registering RDD 360 (countByKey at ColumnProfiler.scala:592) as input to shuffle 29\n",
      "2025-02-20 06:54:59,250 INFO scheduler.DAGScheduler: Got job 61 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:54:59,250 INFO scheduler.DAGScheduler: Final stage: ResultStage 91 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:54:59,250 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "2025-02-20 06:54:59,250 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\n",
      "2025-02-20 06:54:59,251 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:59,256 INFO memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 41.8 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:59,258 INFO memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:59,258 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:59,258 INFO spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,259 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,259 INFO cluster.YarnScheduler: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,261 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,268 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,292 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 31 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,293 INFO scheduler.DAGScheduler: ShuffleMapStage 90 (countByKey at ColumnProfiler.scala:592) finished in 0.042 s\n",
      "2025-02-20 06:54:59,294 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:59,294 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:59,295 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 91)\n",
      "2025-02-20 06:54:59,295 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:59,294 INFO cluster.YarnScheduler: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,295 INFO scheduler.DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:54:59,302 INFO memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.1 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:59,303 INFO memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:54:59,304 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:59,304 INFO spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,305 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,305 INFO cluster.YarnScheduler: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,306 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,311 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,316 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:59,324 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 18 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,324 INFO cluster.YarnScheduler: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,325 INFO scheduler.DAGScheduler: ResultStage 91 (countByKey at ColumnProfiler.scala:592) finished in 0.024 s\n",
      "2025-02-20 06:54:59,326 INFO scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:59,326 INFO cluster.YarnScheduler: Killing all running tasks in stage 91: Stage finished\n",
      "2025-02-20 06:54:59,326 INFO scheduler.DAGScheduler: Job 61 finished: countByKey at ColumnProfiler.scala:592, took 0.077429 s\n",
      "2025-02-20 06:54:59,404 INFO scheduler.DAGScheduler: Registering RDD 366 (collect at AnalysisRunner.scala:326) as input to shuffle 30\n",
      "2025-02-20 06:54:59,404 INFO scheduler.DAGScheduler: Got map stage job 62 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:59,404 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:59,404 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:59,405 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,405 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:59,415 INFO memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 94.7 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:59,416 INFO memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:54:59,416 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.2.254.114:38645 (size: 30.1 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:59,417 INFO spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,417 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,417 INFO cluster.YarnScheduler: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,418 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,425 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on algo-1:42061 (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,550 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 132 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,550 INFO cluster.YarnScheduler: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,550 INFO scheduler.DAGScheduler: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326) finished in 0.143 s\n",
      "2025-02-20 06:54:59,550 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:59,550 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:59,550 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:59,550 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:54:59,572 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:54:59,573 INFO scheduler.DAGScheduler: Got job 63 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:59,575 INFO scheduler.DAGScheduler: Final stage: ResultStage 94 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:59,575 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)\n",
      "2025-02-20 06:54:59,575 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,575 INFO scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:59,579 INFO memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 179.5 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:59,580 INFO memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1456.5 MiB)\n",
      "2025-02-20 06:54:59,581 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:54:59,582 INFO spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,582 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,582 INFO cluster.YarnScheduler: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,583 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 73) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,591 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,599 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 10.2.254.114:38120\n",
      "2025-02-20 06:54:59,654 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 73) in 71 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,654 INFO cluster.YarnScheduler: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,655 INFO scheduler.DAGScheduler: ResultStage 94 (collect at AnalysisRunner.scala:326) finished in 0.078 s\n",
      "2025-02-20 06:54:59,655 INFO scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:59,655 INFO cluster.YarnScheduler: Killing all running tasks in stage 94: Stage finished\n",
      "2025-02-20 06:54:59,656 INFO scheduler.DAGScheduler: Job 63 finished: collect at AnalysisRunner.scala:326, took 0.083464 s\n",
      "2025-02-20 06:54:59,747 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:54:59,748 INFO scheduler.DAGScheduler: Got job 64 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:54:59,748 INFO scheduler.DAGScheduler: Final stage: ResultStage 95 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:54:59,748 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:59,749 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,749 INFO scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:54:59,754 INFO memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 48.9 KiB, free 1456.4 MiB)\n",
      "2025-02-20 06:54:59,755 INFO memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1456.4 MiB)\n",
      "2025-02-20 06:54:59,756 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:54:59,757 INFO spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,757 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,757 INFO cluster.YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,758 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 74) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,767 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,800 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 74) in 42 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,801 INFO scheduler.DAGScheduler: ResultStage 95 (treeReduce at KLLRunner.scala:107) finished in 0.051 s\n",
      "2025-02-20 06:54:59,801 INFO scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:54:59,802 INFO cluster.YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,802 INFO cluster.YarnScheduler: Killing all running tasks in stage 95: Stage finished\n",
      "2025-02-20 06:54:59,807 INFO scheduler.DAGScheduler: Job 64 finished: treeReduce at KLLRunner.scala:107, took 0.059772 s\n",
      "2025-02-20 06:54:59,934 INFO scheduler.DAGScheduler: Registering RDD 384 (collect at AnalysisRunner.scala:326) as input to shuffle 31\n",
      "2025-02-20 06:54:59,934 INFO scheduler.DAGScheduler: Got map stage job 65 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:54:59,935 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:54:59,935 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:54:59,935 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:54:59,936 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:54:59,938 INFO memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 87.4 KiB, free 1456.3 MiB)\n",
      "2025-02-20 06:54:59,940 INFO memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1456.3 MiB)\n",
      "2025-02-20 06:54:59,940 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.2.254.114:38645 (size: 27.3 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:54:59,941 INFO spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:54:59,941 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:54:59,941 INFO cluster.YarnScheduler: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:54:59,942 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 75) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:54:59,951 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on algo-1:42061 (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:54:59,965 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 75) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:54:59,965 INFO cluster.YarnScheduler: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:54:59,966 INFO scheduler.DAGScheduler: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326) finished in 0.029 s\n",
      "2025-02-20 06:54:59,966 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:54:59,967 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:54:59,967 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:54:59,967 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:00,018 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:00,019 INFO scheduler.DAGScheduler: Got job 66 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:00,020 INFO scheduler.DAGScheduler: Final stage: ResultStage 98 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:00,020 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\n",
      "2025-02-20 06:55:00,020 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,021 INFO scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:00,022 INFO memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 67.7 KiB, free 1456.2 MiB)\n",
      "2025-02-20 06:55:00,024 INFO memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.2 MiB)\n",
      "2025-02-20 06:55:00,024 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:00,024 INFO spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,025 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,025 INFO cluster.YarnScheduler: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,026 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 76) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,032 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,035 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:00,038 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 76) in 12 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,038 INFO cluster.YarnScheduler: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,039 INFO scheduler.DAGScheduler: ResultStage 98 (collect at AnalysisRunner.scala:326) finished in 0.018 s\n",
      "2025-02-20 06:55:00,039 INFO scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:00,039 INFO cluster.YarnScheduler: Killing all running tasks in stage 98: Stage finished\n",
      "2025-02-20 06:55:00,039 INFO scheduler.DAGScheduler: Job 66 finished: collect at AnalysisRunner.scala:326, took 0.020630 s\n",
      "2025-02-20 06:55:00,080 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:00,083 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,086 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:00,086 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,090 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:00,091 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,094 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,094 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,109 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,109 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,109 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:55:00,110 INFO scheduler.DAGScheduler: Registering RDD 395 (countByKey at ColumnProfiler.scala:592) as input to shuffle 32\n",
      "2025-02-20 06:55:00,110 INFO scheduler.DAGScheduler: Got job 67 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:55:00,110 INFO scheduler.DAGScheduler: Final stage: ResultStage 100 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:55:00,110 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)\n",
      "2025-02-20 06:55:00,111 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 99)\n",
      "2025-02-20 06:55:00,111 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:00,112 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,115 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,115 INFO memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 41.8 KiB, free 1456.6 MiB)\n",
      "2025-02-20 06:55:00,117 INFO memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:55:00,117 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,117 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,117 INFO spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,118 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,118 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,118 INFO cluster.YarnScheduler: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,119 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,121 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on 10.2.254.114:38645 in memory (size: 17.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:00,122 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on algo-1:42061 in memory (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,123 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:00,126 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,126 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,129 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:00,130 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,132 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:00,133 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,134 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,135 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,137 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on 10.2.254.114:38645 in memory (size: 19.9 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,138 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on algo-1:42061 in memory (size: 19.9 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,141 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on 10.2.254.114:38645 in memory (size: 49.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,148 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on algo-1:42061 in memory (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,150 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on 10.2.254.114:38645 in memory (size: 27.3 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,151 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on algo-1:42061 in memory (size: 27.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,152 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,153 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,155 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,156 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,158 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,160 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,161 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on 10.2.254.114:38645 in memory (size: 30.1 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,163 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on algo-1:42061 in memory (size: 30.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,166 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 47 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,167 INFO cluster.YarnScheduler: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: ShuffleMapStage 99 (countByKey at ColumnProfiler.scala:592) finished in 0.055 s\n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 100)\n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:00,167 INFO scheduler.DAGScheduler: Submitting ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:00,168 INFO memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 5.1 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:55:00,169 INFO memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.1 MiB)\n",
      "2025-02-20 06:55:00,170 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,170 INFO spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,170 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,171 INFO cluster.YarnScheduler: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,172 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,177 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,180 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:00,187 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 15 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,187 INFO cluster.YarnScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,188 INFO scheduler.DAGScheduler: ResultStage 100 (countByKey at ColumnProfiler.scala:592) finished in 0.020 s\n",
      "2025-02-20 06:55:00,189 INFO scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:00,189 INFO cluster.YarnScheduler: Killing all running tasks in stage 100: Stage finished\n",
      "2025-02-20 06:55:00,189 INFO scheduler.DAGScheduler: Job 67 finished: countByKey at ColumnProfiler.scala:592, took 0.079783 s\n",
      "2025-02-20 06:55:00,364 INFO scheduler.DAGScheduler: Registering RDD 401 (collect at AnalysisRunner.scala:326) as input to shuffle 33\n",
      "2025-02-20 06:55:00,364 INFO scheduler.DAGScheduler: Got map stage job 68 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:00,364 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:00,364 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:00,365 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,365 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:00,369 INFO memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 94.7 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:55:00,373 INFO memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1458.0 MiB)\n",
      "2025-02-20 06:55:00,373 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,373 INFO spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,374 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,374 INFO cluster.YarnScheduler: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,375 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,383 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,496 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 121 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,497 INFO cluster.YarnScheduler: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,497 INFO scheduler.DAGScheduler: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326) finished in 0.131 s\n",
      "2025-02-20 06:55:00,497 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:00,497 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:00,497 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:00,497 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:00,529 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:00,530 INFO scheduler.DAGScheduler: Got job 69 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:00,530 INFO scheduler.DAGScheduler: Final stage: ResultStage 103 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:00,530 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\n",
      "2025-02-20 06:55:00,530 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,530 INFO scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:00,536 INFO memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 179.5 KiB, free 1457.8 MiB)\n",
      "2025-02-20 06:55:00,537 INFO memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 49.1 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:55:00,537 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.2.254.114:38645 (size: 49.1 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:00,538 INFO spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,538 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,538 INFO cluster.YarnScheduler: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,539 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,546 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on algo-1:42061 (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,555 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:00,622 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 83 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,622 INFO cluster.YarnScheduler: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,623 INFO scheduler.DAGScheduler: ResultStage 103 (collect at AnalysisRunner.scala:326) finished in 0.092 s\n",
      "2025-02-20 06:55:00,625 INFO scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:00,625 INFO cluster.YarnScheduler: Killing all running tasks in stage 103: Stage finished\n",
      "2025-02-20 06:55:00,625 INFO scheduler.DAGScheduler: Job 69 finished: collect at AnalysisRunner.scala:326, took 0.096042 s\n",
      "2025-02-20 06:55:00,711 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:55:00,712 INFO scheduler.DAGScheduler: Got job 70 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:55:00,712 INFO scheduler.DAGScheduler: Final stage: ResultStage 104 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:55:00,712 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:00,712 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,712 INFO scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:55:00,717 INFO memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 48.9 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:55:00,718 INFO memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.7 MiB)\n",
      "2025-02-20 06:55:00,718 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,719 INFO spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,719 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,719 INFO cluster.YarnScheduler: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,721 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 81) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,727 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,771 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 81) in 51 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,771 INFO cluster.YarnScheduler: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,771 INFO scheduler.DAGScheduler: ResultStage 104 (treeReduce at KLLRunner.scala:107) finished in 0.058 s\n",
      "2025-02-20 06:55:00,772 INFO scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:00,772 INFO cluster.YarnScheduler: Killing all running tasks in stage 104: Stage finished\n",
      "2025-02-20 06:55:00,772 INFO scheduler.DAGScheduler: Job 70 finished: treeReduce at KLLRunner.scala:107, took 0.060926 s\n",
      "2025-02-20 06:55:00,855 INFO scheduler.DAGScheduler: Registering RDD 419 (collect at AnalysisRunner.scala:326) as input to shuffle 34\n",
      "2025-02-20 06:55:00,855 INFO scheduler.DAGScheduler: Got map stage job 71 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:00,855 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:00,855 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:00,855 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,856 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:00,858 INFO memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 87.4 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:55:00,859 INFO memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1457.6 MiB)\n",
      "2025-02-20 06:55:00,859 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,860 INFO spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,860 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,860 INFO cluster.YarnScheduler: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,861 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 82) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,867 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,878 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 82) in 17 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,879 INFO cluster.YarnScheduler: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,879 INFO scheduler.DAGScheduler: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326) finished in 0.023 s\n",
      "2025-02-20 06:55:00,879 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:00,879 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:00,879 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:00,879 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:00,916 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:00,916 INFO scheduler.DAGScheduler: Got job 72 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:00,916 INFO scheduler.DAGScheduler: Final stage: ResultStage 107 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:00,916 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\n",
      "2025-02-20 06:55:00,916 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:00,916 INFO scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:00,918 INFO memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 67.7 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:55:00,919 INFO memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1457.5 MiB)\n",
      "2025-02-20 06:55:00,919 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,920 INFO spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,920 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,920 INFO cluster.YarnScheduler: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,921 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,928 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,930 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:00,934 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 13 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,934 INFO cluster.YarnScheduler: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,935 INFO scheduler.DAGScheduler: ResultStage 107 (collect at AnalysisRunner.scala:326) finished in 0.018 s\n",
      "2025-02-20 06:55:00,935 INFO scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:00,936 INFO cluster.YarnScheduler: Killing all running tasks in stage 107: Stage finished\n",
      "2025-02-20 06:55:00,936 INFO scheduler.DAGScheduler: Job 72 finished: collect at AnalysisRunner.scala:326, took 0.020184 s\n",
      "2025-02-20 06:55:00,967 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:55:00,968 INFO scheduler.DAGScheduler: Registering RDD 430 (countByKey at ColumnProfiler.scala:592) as input to shuffle 35\n",
      "2025-02-20 06:55:00,968 INFO scheduler.DAGScheduler: Got job 73 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:55:00,968 INFO scheduler.DAGScheduler: Final stage: ResultStage 109 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:55:00,968 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\n",
      "2025-02-20 06:55:00,968 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 108)\n",
      "2025-02-20 06:55:00,969 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:00,971 INFO memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 41.8 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:55:00,972 INFO memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:55:00,973 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.2.254.114:38645 (size: 17.3 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:00,973 INFO spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:00,973 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:00,973 INFO cluster.YarnScheduler: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:00,974 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 84) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:00,979 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on algo-1:42061 (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:00,997 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 84) in 23 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:00,997 INFO cluster.YarnScheduler: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:00,997 INFO scheduler.DAGScheduler: ShuffleMapStage 108 (countByKey at ColumnProfiler.scala:592) finished in 0.028 s\n",
      "2025-02-20 06:55:00,998 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:00,998 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:00,998 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 109)\n",
      "2025-02-20 06:55:00,998 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:00,998 INFO scheduler.DAGScheduler: Submitting ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:00,999 INFO memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:55:01,000 INFO memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\n",
      "2025-02-20 06:55:01,000 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:01,001 INFO spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,001 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,001 INFO cluster.YarnScheduler: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,002 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 85) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,007 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,009 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:01,016 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 85) in 14 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,016 INFO cluster.YarnScheduler: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,019 INFO scheduler.DAGScheduler: ResultStage 109 (countByKey at ColumnProfiler.scala:592) finished in 0.021 s\n",
      "2025-02-20 06:55:01,020 INFO scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:01,020 INFO cluster.YarnScheduler: Killing all running tasks in stage 109: Stage finished\n",
      "2025-02-20 06:55:01,021 INFO scheduler.DAGScheduler: Job 73 finished: countByKey at ColumnProfiler.scala:592, took 0.053829 s\n",
      "2025-02-20 06:55:01,087 INFO scheduler.DAGScheduler: Registering RDD 436 (collect at AnalysisRunner.scala:326) as input to shuffle 36\n",
      "2025-02-20 06:55:01,087 INFO scheduler.DAGScheduler: Got map stage job 74 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:01,087 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:01,087 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:01,088 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:01,088 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:01,092 INFO memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 94.7 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:55:01,094 INFO memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 1457.3 MiB)\n",
      "2025-02-20 06:55:01,094 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.2.254.114:38645 (size: 30.2 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:01,094 INFO spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,095 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,095 INFO cluster.YarnScheduler: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,096 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 86) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,110 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on algo-1:42061 (size: 30.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,234 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 86) in 138 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,234 INFO cluster.YarnScheduler: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,235 INFO scheduler.DAGScheduler: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326) finished in 0.146 s\n",
      "2025-02-20 06:55:01,235 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:01,235 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:01,235 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:01,235 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:01,259 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:01,259 INFO scheduler.DAGScheduler: Got job 75 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:01,259 INFO scheduler.DAGScheduler: Final stage: ResultStage 112 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:01,259 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)\n",
      "2025-02-20 06:55:01,259 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:01,260 INFO scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:01,264 INFO memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 179.6 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:55:01,266 INFO memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 1457.1 MiB)\n",
      "2025-02-20 06:55:01,266 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.2.254.114:38645 (size: 49.2 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:01,267 INFO spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,267 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,267 INFO cluster.YarnScheduler: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,268 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 87) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,273 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on algo-1:42061 (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,281 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:01,352 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 87) in 84 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,353 INFO cluster.YarnScheduler: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,353 INFO scheduler.DAGScheduler: ResultStage 112 (collect at AnalysisRunner.scala:326) finished in 0.093 s\n",
      "2025-02-20 06:55:01,353 INFO scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:01,353 INFO cluster.YarnScheduler: Killing all running tasks in stage 112: Stage finished\n",
      "2025-02-20 06:55:01,354 INFO scheduler.DAGScheduler: Job 75 finished: collect at AnalysisRunner.scala:326, took 0.094788 s\n",
      "2025-02-20 06:55:01,413 INFO codegen.CodeGenerator: Code generated in 8.997684 ms\n",
      "2025-02-20 06:55:01,440 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:55:01,442 INFO scheduler.DAGScheduler: Got job 76 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:55:01,442 INFO scheduler.DAGScheduler: Final stage: ResultStage 113 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:55:01,442 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:01,442 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:01,443 INFO scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:55:01,447 INFO memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 48.9 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:55:01,449 INFO memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.0 MiB)\n",
      "2025-02-20 06:55:01,449 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:01,450 INFO spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,450 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,450 INFO cluster.YarnScheduler: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,451 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 88) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,460 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,525 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 88) in 74 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,525 INFO cluster.YarnScheduler: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,526 INFO scheduler.DAGScheduler: ResultStage 113 (treeReduce at KLLRunner.scala:107) finished in 0.083 s\n",
      "2025-02-20 06:55:01,526 INFO scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:01,527 INFO cluster.YarnScheduler: Killing all running tasks in stage 113: Stage finished\n",
      "2025-02-20 06:55:01,527 INFO scheduler.DAGScheduler: Job 76 finished: treeReduce at KLLRunner.scala:107, took 0.086206 s\n",
      "2025-02-20 06:55:01,671 INFO codegen.CodeGenerator: Code generated in 43.72849 ms\n",
      "2025-02-20 06:55:01,677 INFO scheduler.DAGScheduler: Registering RDD 454 (collect at AnalysisRunner.scala:326) as input to shuffle 37\n",
      "2025-02-20 06:55:01,677 INFO scheduler.DAGScheduler: Got map stage job 77 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:01,677 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:01,678 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:01,678 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:01,678 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:01,681 INFO memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 87.4 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:55:01,683 INFO memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1456.9 MiB)\n",
      "2025-02-20 06:55:01,683 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:01,684 INFO spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,684 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,684 INFO cluster.YarnScheduler: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,685 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 89) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,695 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,821 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 89) in 136 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,821 INFO cluster.YarnScheduler: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,822 INFO scheduler.DAGScheduler: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326) finished in 0.143 s\n",
      "2025-02-20 06:55:01,828 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:01,829 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:01,830 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:01,830 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:01,904 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:01,905 INFO scheduler.DAGScheduler: Got job 78 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:01,906 INFO scheduler.DAGScheduler: Final stage: ResultStage 116 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:01,906 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)\n",
      "2025-02-20 06:55:01,906 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:01,907 INFO scheduler.DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:01,910 INFO memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 67.7 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:55:01,911 INFO memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:55:01,912 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:01,912 INFO spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:01,913 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:01,913 INFO cluster.YarnScheduler: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:01,914 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 90) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:01,935 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:01,940 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:01,952 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 90) in 38 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:01,952 INFO cluster.YarnScheduler: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:01,953 INFO scheduler.DAGScheduler: ResultStage 116 (collect at AnalysisRunner.scala:326) finished in 0.045 s\n",
      "2025-02-20 06:55:01,953 INFO scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:01,954 INFO cluster.YarnScheduler: Killing all running tasks in stage 116: Stage finished\n",
      "2025-02-20 06:55:01,954 INFO scheduler.DAGScheduler: Job 78 finished: collect at AnalysisRunner.scala:326, took 0.049089 s\n",
      "2025-02-20 06:55:02,020 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:55:02,021 INFO scheduler.DAGScheduler: Registering RDD 465 (countByKey at ColumnProfiler.scala:592) as input to shuffle 38\n",
      "2025-02-20 06:55:02,022 INFO scheduler.DAGScheduler: Got job 79 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:55:02,022 INFO scheduler.DAGScheduler: Final stage: ResultStage 118 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:55:02,022 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)\n",
      "2025-02-20 06:55:02,022 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 117)\n",
      "2025-02-20 06:55:02,023 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:02,028 INFO memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 41.8 KiB, free 1456.8 MiB)\n",
      "2025-02-20 06:55:02,029 INFO memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:55:02,029 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.2.254.114:38645 (size: 17.4 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:02,030 INFO spark.SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,030 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,030 INFO cluster.YarnScheduler: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,036 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 91) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,045 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on algo-1:42061 (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,078 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 91) in 42 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,078 INFO cluster.YarnScheduler: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: ShuffleMapStage 117 (countByKey at ColumnProfiler.scala:592) finished in 0.054 s\n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 118)\n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:02,078 INFO scheduler.DAGScheduler: Submitting ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:02,080 INFO memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:55:02,081 INFO memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\n",
      "2025-02-20 06:55:02,085 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:02,085 INFO spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,086 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,086 INFO cluster.YarnScheduler: Adding task set 118.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,086 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 92) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,094 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,096 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:02,108 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 92) in 22 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,109 INFO cluster.YarnScheduler: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,109 INFO scheduler.DAGScheduler: ResultStage 118 (countByKey at ColumnProfiler.scala:592) finished in 0.030 s\n",
      "2025-02-20 06:55:02,109 INFO scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:02,109 INFO cluster.YarnScheduler: Killing all running tasks in stage 118: Stage finished\n",
      "2025-02-20 06:55:02,109 INFO scheduler.DAGScheduler: Job 79 finished: countByKey at ColumnProfiler.scala:592, took 0.088441 s\n",
      "2025-02-20 06:55:02,235 INFO scheduler.DAGScheduler: Registering RDD 471 (collect at AnalysisRunner.scala:326) as input to shuffle 39\n",
      "2025-02-20 06:55:02,235 INFO scheduler.DAGScheduler: Got map stage job 80 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:02,235 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:02,235 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:02,236 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:02,236 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:02,243 INFO memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 94.7 KiB, free 1456.6 MiB)\n",
      "2025-02-20 06:55:02,244 INFO memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 1456.6 MiB)\n",
      "2025-02-20 06:55:02,245 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.2.254.114:38645 (size: 30.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:02,245 INFO spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,246 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,246 INFO cluster.YarnScheduler: Adding task set 119.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,247 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 93) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,256 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on algo-1:42061 (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,393 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 93) in 146 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,393 INFO cluster.YarnScheduler: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,394 INFO scheduler.DAGScheduler: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326) finished in 0.156 s\n",
      "2025-02-20 06:55:02,397 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:02,397 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:02,397 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:02,397 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:02,432 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:02,433 INFO scheduler.DAGScheduler: Got job 81 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:02,433 INFO scheduler.DAGScheduler: Final stage: ResultStage 121 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:02,433 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)\n",
      "2025-02-20 06:55:02,433 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:02,433 INFO scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:02,440 INFO memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 179.7 KiB, free 1456.4 MiB)\n",
      "2025-02-20 06:55:02,441 INFO memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 49.3 KiB, free 1456.4 MiB)\n",
      "2025-02-20 06:55:02,442 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.2.254.114:38645 (size: 49.3 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,443 INFO spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,443 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,443 INFO cluster.YarnScheduler: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,444 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 94) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,451 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on algo-1:42061 (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,461 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:02,537 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 94) in 93 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,537 INFO cluster.YarnScheduler: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,538 INFO scheduler.DAGScheduler: ResultStage 121 (collect at AnalysisRunner.scala:326) finished in 0.104 s\n",
      "2025-02-20 06:55:02,539 INFO scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:02,539 INFO cluster.YarnScheduler: Killing all running tasks in stage 121: Stage finished\n",
      "2025-02-20 06:55:02,539 INFO scheduler.DAGScheduler: Job 81 finished: collect at AnalysisRunner.scala:326, took 0.107090 s\n",
      "2025-02-20 06:55:02,660 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\n",
      "2025-02-20 06:55:02,661 INFO scheduler.DAGScheduler: Got job 82 (treeReduce at KLLRunner.scala:107) with 1 output partitions\n",
      "2025-02-20 06:55:02,661 INFO scheduler.DAGScheduler: Final stage: ResultStage 122 (treeReduce at KLLRunner.scala:107)\n",
      "2025-02-20 06:55:02,661 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:02,661 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:02,661 INFO scheduler.DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107), which has no missing parents\n",
      "2025-02-20 06:55:02,668 INFO memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 48.9 KiB, free 1456.3 MiB)\n",
      "2025-02-20 06:55:02,671 INFO memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1456.3 MiB)\n",
      "2025-02-20 06:55:02,671 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.2.254.114:38645 (size: 19.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,672 INFO spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,672 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,672 INFO cluster.YarnScheduler: Adding task set 122.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,673 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 95) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4969 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,678 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on algo-1:42061 (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,710 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 95) in 37 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,710 INFO cluster.YarnScheduler: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,711 INFO scheduler.DAGScheduler: ResultStage 122 (treeReduce at KLLRunner.scala:107) finished in 0.049 s\n",
      "2025-02-20 06:55:02,711 INFO scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:02,712 INFO cluster.YarnScheduler: Killing all running tasks in stage 122: Stage finished\n",
      "2025-02-20 06:55:02,714 INFO scheduler.DAGScheduler: Job 82 finished: treeReduce at KLLRunner.scala:107, took 0.053731 s\n",
      "2025-02-20 06:55:02,800 INFO scheduler.DAGScheduler: Registering RDD 489 (collect at AnalysisRunner.scala:326) as input to shuffle 40\n",
      "2025-02-20 06:55:02,800 INFO scheduler.DAGScheduler: Got map stage job 83 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:02,801 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:02,801 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:02,801 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:02,801 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:02,803 INFO memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 87.4 KiB, free 1456.2 MiB)\n",
      "2025-02-20 06:55:02,804 INFO memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 1456.2 MiB)\n",
      "2025-02-20 06:55:02,804 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.2.254.114:38645 (size: 27.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,805 INFO spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,805 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,805 INFO cluster.YarnScheduler: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,806 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 96) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,812 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on algo-1:42061 (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,830 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 96) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,830 INFO scheduler.DAGScheduler: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326) finished in 0.028 s\n",
      "2025-02-20 06:55:02,830 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:02,831 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:02,831 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:02,831 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:02,831 INFO cluster.YarnScheduler: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,872 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\n",
      "2025-02-20 06:55:02,872 INFO scheduler.DAGScheduler: Got job 84 (collect at AnalysisRunner.scala:326) with 1 output partitions\n",
      "2025-02-20 06:55:02,872 INFO scheduler.DAGScheduler: Final stage: ResultStage 125 (collect at AnalysisRunner.scala:326)\n",
      "2025-02-20 06:55:02,872 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\n",
      "2025-02-20 06:55:02,872 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:02,873 INFO scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326), which has no missing parents\n",
      "2025-02-20 06:55:02,874 INFO memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 67.7 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,875 INFO memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,875 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.2.254.114:38645 (size: 19.8 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,876 INFO spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,876 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,876 INFO cluster.YarnScheduler: Adding task set 125.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,877 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 97) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,884 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on algo-1:42061 (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,886 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:02,890 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 97) in 13 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,890 INFO cluster.YarnScheduler: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,890 INFO scheduler.DAGScheduler: ResultStage 125 (collect at AnalysisRunner.scala:326) finished in 0.017 s\n",
      "2025-02-20 06:55:02,891 INFO scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:02,891 INFO cluster.YarnScheduler: Killing all running tasks in stage 125: Stage finished\n",
      "2025-02-20 06:55:02,891 INFO scheduler.DAGScheduler: Job 84 finished: collect at AnalysisRunner.scala:326, took 0.019370 s\n",
      "2025-02-20 06:55:02,925 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\n",
      "2025-02-20 06:55:02,926 INFO scheduler.DAGScheduler: Registering RDD 500 (countByKey at ColumnProfiler.scala:592) as input to shuffle 41\n",
      "2025-02-20 06:55:02,926 INFO scheduler.DAGScheduler: Got job 85 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\n",
      "2025-02-20 06:55:02,926 INFO scheduler.DAGScheduler: Final stage: ResultStage 127 (countByKey at ColumnProfiler.scala:592)\n",
      "2025-02-20 06:55:02,926 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)\n",
      "2025-02-20 06:55:02,926 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 126)\n",
      "2025-02-20 06:55:02,927 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:02,929 INFO memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 41.8 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,933 INFO memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,933 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.2.254.114:38645 (size: 17.3 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,934 INFO spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,934 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,934 INFO cluster.YarnScheduler: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,935 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 98) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,940 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on algo-1:42061 (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,959 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 98) in 25 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,959 INFO cluster.YarnScheduler: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: ShuffleMapStage 126 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 127)\n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:02,960 INFO scheduler.DAGScheduler: Submitting ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592), which has no missing parents\n",
      "2025-02-20 06:55:02,961 INFO memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 5.1 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,966 INFO memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.1 MiB)\n",
      "2025-02-20 06:55:02,966 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.2.254.114:38645 (size: 3.0 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:02,966 INFO spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:02,967 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:02,967 INFO cluster.YarnScheduler: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:02,968 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 99) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:02,976 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on algo-1:42061 (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:02,978 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:02,988 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 99) in 20 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:02,988 INFO cluster.YarnScheduler: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:02,989 INFO scheduler.DAGScheduler: ResultStage 127 (countByKey at ColumnProfiler.scala:592) finished in 0.028 s\n",
      "2025-02-20 06:55:02,989 INFO scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:02,989 INFO cluster.YarnScheduler: Killing all running tasks in stage 127: Stage finished\n",
      "2025-02-20 06:55:02,989 INFO scheduler.DAGScheduler: Job 85 finished: countByKey at ColumnProfiler.scala:592, took 0.063700 s\n",
      "2025-02-20 06:55:03,221 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\n",
      "2025-02-20 06:55:03,262 INFO codegen.CodeGenerator: Code generated in 8.668274 ms\n",
      "2025-02-20 06:55:03,266 INFO scheduler.DAGScheduler: Registering RDD 506 (count at StatsGenerator.scala:66) as input to shuffle 42\n",
      "2025-02-20 06:55:03,266 INFO scheduler.DAGScheduler: Got map stage job 86 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2025-02-20 06:55:03,266 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 128 (count at StatsGenerator.scala:66)\n",
      "2025-02-20 06:55:03,266 INFO scheduler.DAGScheduler: Parents of final stage: List()\n",
      "2025-02-20 06:55:03,267 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:03,267 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[506] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2025-02-20 06:55:03,269 INFO memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 34.1 KiB, free 1456.0 MiB)\n",
      "2025-02-20 06:55:03,272 INFO memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 1456.0 MiB)\n",
      "2025-02-20 06:55:03,273 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.2.254.114:38645 (size: 13.7 KiB, free: 1458.0 MiB)\n",
      "2025-02-20 06:55:03,273 INFO spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:03,273 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[506] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:03,273 INFO cluster.YarnScheduler: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:03,274 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 100) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4958 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:03,279 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on algo-1:42061 (size: 13.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,305 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 100) in 31 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:03,305 INFO cluster.YarnScheduler: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:03,306 INFO scheduler.DAGScheduler: ShuffleMapStage 128 (count at StatsGenerator.scala:66) finished in 0.039 s\n",
      "2025-02-20 06:55:03,306 INFO scheduler.DAGScheduler: looking for newly runnable stages\n",
      "2025-02-20 06:55:03,306 INFO scheduler.DAGScheduler: running: Set()\n",
      "2025-02-20 06:55:03,306 INFO scheduler.DAGScheduler: waiting: Set()\n",
      "2025-02-20 06:55:03,306 INFO scheduler.DAGScheduler: failed: Set()\n",
      "2025-02-20 06:55:03,329 INFO codegen.CodeGenerator: Code generated in 13.385226 ms\n",
      "2025-02-20 06:55:03,341 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\n",
      "2025-02-20 06:55:03,342 INFO scheduler.DAGScheduler: Got job 87 (count at StatsGenerator.scala:66) with 1 output partitions\n",
      "2025-02-20 06:55:03,342 INFO scheduler.DAGScheduler: Final stage: ResultStage 130 (count at StatsGenerator.scala:66)\n",
      "2025-02-20 06:55:03,342 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\n",
      "2025-02-20 06:55:03,342 INFO scheduler.DAGScheduler: Missing parents: List()\n",
      "2025-02-20 06:55:03,342 INFO scheduler.DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[509] at count at StatsGenerator.scala:66), which has no missing parents\n",
      "2025-02-20 06:55:03,344 INFO memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 11.1 KiB, free 1456.0 MiB)\n",
      "2025-02-20 06:55:03,347 INFO memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1456.0 MiB)\n",
      "2025-02-20 06:55:03,347 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.2.254.114:38645 (size: 5.5 KiB, free: 1458.0 MiB)\n",
      "2025-02-20 06:55:03,347 INFO spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\n",
      "2025-02-20 06:55:03,348 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[509] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\n",
      "2025-02-20 06:55:03,348 INFO cluster.YarnScheduler: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "2025-02-20 06:55:03,349 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 101) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\n",
      "2025-02-20 06:55:03,354 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on algo-1:42061 (size: 5.5 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,357 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 10.2.254.114:38120\n",
      "2025-02-20 06:55:03,401 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:03,402 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,405 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on 10.2.254.114:38645 in memory (size: 49.3 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:03,408 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on algo-1:42061 in memory (size: 49.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,411 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.1 MiB)\n",
      "2025-02-20 06:55:03,411 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,413 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,414 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,418 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,420 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,421 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on 10.2.254.114:38645 in memory (size: 17.3 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,422 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on algo-1:42061 in memory (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,424 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,424 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 101) in 75 ms on algo-1 (executor 1) (1/1)\n",
      "2025-02-20 06:55:03,424 INFO cluster.YarnScheduler: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "2025-02-20 06:55:03,425 INFO scheduler.DAGScheduler: ResultStage 130 (count at StatsGenerator.scala:66) finished in 0.082 s\n",
      "2025-02-20 06:55:03,426 INFO scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "2025-02-20 06:55:03,426 INFO cluster.YarnScheduler: Killing all running tasks in stage 130: Stage finished\n",
      "2025-02-20 06:55:03,426 INFO scheduler.DAGScheduler: Job 87 finished: count at StatsGenerator.scala:66, took 0.084813 s\n",
      "2025-02-20 06:55:03,432 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,438 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,439 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,441 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on 10.2.254.114:38645 in memory (size: 30.2 KiB, free: 1458.2 MiB)\n",
      "2025-02-20 06:55:03,442 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on algo-1:42061 in memory (size: 30.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,443 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,444 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,446 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,447 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,449 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,450 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,451 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on 10.2.254.114:38645 in memory (size: 17.3 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,452 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on algo-1:42061 in memory (size: 17.3 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,453 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on 10.2.254.114:38645 in memory (size: 17.4 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,454 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on algo-1:42061 in memory (size: 17.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,456 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,459 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,460 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on 10.2.254.114:38645 in memory (size: 13.7 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,461 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on algo-1:42061 in memory (size: 13.7 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,463 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on 10.2.254.114:38645 in memory (size: 3.0 KiB, free: 1458.3 MiB)\n",
      "2025-02-20 06:55:03,465 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on algo-1:42061 in memory (size: 3.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,467 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:03,468 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,470 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on 10.2.254.114:38645 in memory (size: 19.8 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:03,472 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on algo-1:42061 in memory (size: 19.8 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,474 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on 10.2.254.114:38645 in memory (size: 49.1 KiB, free: 1458.4 MiB)\n",
      "2025-02-20 06:55:03,478 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on algo-1:42061 in memory (size: 49.1 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,482 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on 10.2.254.114:38645 in memory (size: 49.2 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:03,484 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on algo-1:42061 in memory (size: 49.2 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,486 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on 10.2.254.114:38645 in memory (size: 19.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:03,487 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on algo-1:42061 in memory (size: 19.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,488 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on 10.2.254.114:38645 in memory (size: 27.4 KiB, free: 1458.5 MiB)\n",
      "2025-02-20 06:55:03,489 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on algo-1:42061 in memory (size: 27.4 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,490 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on 10.2.254.114:38645 in memory (size: 30.0 KiB, free: 1458.6 MiB)\n",
      "2025-02-20 06:55:03,492 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on algo-1:42061 in memory (size: 30.0 KiB, free: 5.8 GiB)\n",
      "2025-02-20 06:55:03,946 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\n",
      "2025-02-20 06:55:03,959 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\n",
      "2025-02-20 06:55:04,050 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\n",
      "2025-02-20 06:55:04,051 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
      "2025-02-20 06:55:04,056 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\n",
      "2025-02-20 06:55:04,078 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "2025-02-20 06:55:04,156 INFO memory.MemoryStore: MemoryStore cleared\n",
      "2025-02-20 06:55:04,158 INFO storage.BlockManager: BlockManager stopped\n",
      "2025-02-20 06:55:04,173 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "2025-02-20 06:55:04,182 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "2025-02-20 06:55:04,256 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "2025-02-20 06:55:04,257 INFO Main: Completed: Job completed successfully with no violations.\n",
      "2025-02-20 06:55:04,257 INFO Main: Write to file /opt/ml/output/message.\n",
      "2025-02-20 06:55:04,298 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "2025-02-20 06:55:04,299 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4037aa19-3ff0-4a5d-8d4e-97888931a648\n",
      "2025-02-20 06:55:04,312 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-5227e485-73ff-4d66-9c1e-ce3c51ad0c50\n",
      "2025-02-20 06:55:04,478 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\n",
      "2025-02-20 06:55:04,479 - DefaultDataAnalyzer - INFO - Spark job completed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x15c606e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=360,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri + \"/training-dataset-with-header.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b2a3d",
   "metadata": {
    "papermill": {
     "duration": 0.048105,
     "end_time": "2022-04-18T00:29:46.442994",
     "exception": false,
     "start_time": "2022-04-18T00:29:46.394889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Explore the generated constraints and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5298eea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:46.551577Z",
     "iopub.status.busy": "2022-04-18T00:29:46.550580Z",
     "iopub.status.idle": "2022-04-18T00:29:46.717774Z",
     "shell.execute_reply": "2022-04-18T00:29:46.718169Z"
    },
    "papermill": {
     "duration": 0.227209,
     "end_time": "2022-04-18T00:29:46.718320",
     "exception": false,
     "start_time": "2022-04-18T00:29:46.491111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:31:00] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:31:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=339370;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=950120;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Files:\n",
      "sagemaker/ModelMonitor/baselining/results/constraints.json\n",
      " sagemaker/ModelMonitor/baselining/results/statistics.json\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6179805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:46.819261Z",
     "iopub.status.busy": "2022-04-18T00:29:46.818492Z",
     "iopub.status.idle": "2022-04-18T00:29:47.210196Z",
     "shell.execute_reply": "2022-04-18T00:29:47.209794Z"
    },
    "papermill": {
     "duration": 0.444019,
     "end_time": "2022-04-18T00:29:47.210306",
     "exception": false,
     "start_time": "2022-04-18T00:29:46.766287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.approximate_num_distinct_values</th>\n",
       "      <th>numerical_statistics.completeness</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139306</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.346265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Length</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>101.276897</td>\n",
       "      <td>236279.0</td>\n",
       "      <td>39.552442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 25.2, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[119.0, 100.0, 111.0, 181.0, 95.0, 104.0, 70....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VMail Message</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>8.214316</td>\n",
       "      <td>19164.0</td>\n",
       "      <td>13.776908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 5.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[19.0, 0.0, 0.0, 40.0, 36.0, 0.0, 0.0, 24.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>180.226489</td>\n",
       "      <td>420468.4</td>\n",
       "      <td>53.987179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.8</td>\n",
       "      <td>1466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 35.08, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[178.1, 160.3, 197.1, 105.2, 283.1, 113.6, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>100.259323</td>\n",
       "      <td>233905.0</td>\n",
       "      <td>20.165008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 16.5, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[110.0, 138.0, 117.0, 61.0, 112.0, 87.0, 122....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eve Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>200.050107</td>\n",
       "      <td>466716.9</td>\n",
       "      <td>50.015928</td>\n",
       "      <td>31.2</td>\n",
       "      <td>361.8</td>\n",
       "      <td>1339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 31.2, 'upper_bound': 64.26, '...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[212.8, 221.3, 227.8, 341.3, 286.2, 158.6, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eve Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>99.573939</td>\n",
       "      <td>232306.0</td>\n",
       "      <td>19.675578</td>\n",
       "      <td>12.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 12.0, 'upper_bound': 27.8, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[100.0, 92.0, 128.0, 79.0, 86.0, 98.0, 112.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Night Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>201.388598</td>\n",
       "      <td>469839.6</td>\n",
       "      <td>50.627961</td>\n",
       "      <td>23.2</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 23.2, 'upper_bound': 60.37999...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[226.3, 150.4, 214.0, 165.7, 261.7, 187.7, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Night Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>100.227175</td>\n",
       "      <td>233830.0</td>\n",
       "      <td>19.282029</td>\n",
       "      <td>42.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 42.0, 'upper_bound': 55.3, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[123.0, 120.0, 101.0, 97.0, 129.0, 87.0, 112....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Intl Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>10.253065</td>\n",
       "      <td>23920.4</td>\n",
       "      <td>2.778766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 1.8399999...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[10.0, 11.2, 9.3, 6.3, 11.3, 10.5, 0.0, 9.7, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0           Churn      Integral                                     2333   \n",
       "1  Account Length      Integral                                     2333   \n",
       "2   VMail Message      Integral                                     2333   \n",
       "3        Day Mins    Fractional                                     2333   \n",
       "4       Day Calls      Integral                                     2333   \n",
       "5        Eve Mins    Fractional                                     2333   \n",
       "6       Eve Calls      Integral                                     2333   \n",
       "7      Night Mins    Fractional                                     2333   \n",
       "8     Night Calls      Integral                                     2333   \n",
       "9       Intl Mins    Fractional                                     2333   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.139306   \n",
       "1                                        0                 101.276897   \n",
       "2                                        0                   8.214316   \n",
       "3                                        0                 180.226489   \n",
       "4                                        0                 100.259323   \n",
       "5                                        0                 200.050107   \n",
       "6                                        0                  99.573939   \n",
       "7                                        0                 201.388598   \n",
       "8                                        0                 100.227175   \n",
       "9                                        0                  10.253065   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                     325.0                      0.346265   \n",
       "1                  236279.0                     39.552442   \n",
       "2                   19164.0                     13.776908   \n",
       "3                  420468.4                     53.987179   \n",
       "4                  233905.0                     20.165008   \n",
       "5                  466716.9                     50.015928   \n",
       "6                  232306.0                     19.675578   \n",
       "7                  469839.6                     50.627961   \n",
       "8                  233830.0                     19.282029   \n",
       "9                   23920.4                      2.778766   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                       0.0                       1.0   \n",
       "1                       1.0                     243.0   \n",
       "2                       0.0                      51.0   \n",
       "3                       0.0                     350.8   \n",
       "4                       0.0                     165.0   \n",
       "5                      31.2                     361.8   \n",
       "6                      12.0                     170.0   \n",
       "7                      23.2                     395.0   \n",
       "8                      42.0                     175.0   \n",
       "9                       0.0                      18.4   \n",
       "\n",
       "   numerical_statistics.approximate_num_distinct_values  \\\n",
       "0                                                  2      \n",
       "1                                                208      \n",
       "2                                                 45      \n",
       "3                                               1466      \n",
       "4                                                115      \n",
       "5                                               1339      \n",
       "6                                                118      \n",
       "7                                               1401      \n",
       "8                                                110      \n",
       "9                                                155      \n",
       "\n",
       "   numerical_statistics.completeness  \\\n",
       "0                                1.0   \n",
       "1                                1.0   \n",
       "2                                1.0   \n",
       "3                                1.0   \n",
       "4                                1.0   \n",
       "5                                1.0   \n",
       "6                                1.0   \n",
       "7                                1.0   \n",
       "8                                1.0   \n",
       "9                                1.0   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 1.0, 'upper_bound': 25.2, 'co...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 5.1, 'cou...   \n",
       "3  [{'lower_bound': 0.0, 'upper_bound': 35.08, 'c...   \n",
       "4  [{'lower_bound': 0.0, 'upper_bound': 16.5, 'co...   \n",
       "5  [{'lower_bound': 31.2, 'upper_bound': 64.26, '...   \n",
       "6  [{'lower_bound': 12.0, 'upper_bound': 27.8, 'c...   \n",
       "7  [{'lower_bound': 23.2, 'upper_bound': 60.37999...   \n",
       "8  [{'lower_bound': 42.0, 'upper_bound': 55.3, 'c...   \n",
       "9  [{'lower_bound': 0.0, 'upper_bound': 1.8399999...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...  \n",
       "1  [[119.0, 100.0, 111.0, 181.0, 95.0, 104.0, 70....  \n",
       "2  [[19.0, 0.0, 0.0, 40.0, 36.0, 0.0, 0.0, 24.0, ...  \n",
       "3  [[178.1, 160.3, 197.1, 105.2, 283.1, 113.6, 23...  \n",
       "4  [[110.0, 138.0, 117.0, 61.0, 112.0, 87.0, 122....  \n",
       "5  [[212.8, 221.3, 227.8, 341.3, 286.2, 158.6, 29...  \n",
       "6  [[100.0, 92.0, 128.0, 79.0, 86.0, 98.0, 112.0,...  \n",
       "7  [[226.3, 150.4, 214.0, 165.7, 261.7, 187.7, 20...  \n",
       "8  [[123.0, 120.0, 101.0, 97.0, 129.0, 87.0, 112....  \n",
       "9  [[10.0, 11.2, 9.3, 6.3, 11.3, 10.5, 0.0, 9.7, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d25691b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:47.317888Z",
     "iopub.status.busy": "2022-04-18T00:29:47.317350Z",
     "iopub.status.idle": "2022-04-18T00:29:47.392290Z",
     "shell.execute_reply": "2022-04-18T00:29:47.391919Z"
    },
    "papermill": {
     "duration": 0.132679,
     "end_time": "2022-04-18T00:29:47.392401",
     "exception": false,
     "start_time": "2022-04-18T00:29:47.259722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Length</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VMail Message</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eve Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eve Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Night Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Night Calls</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Intl Mins</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0           Churn      Integral           1.0                             True\n",
       "1  Account Length      Integral           1.0                             True\n",
       "2   VMail Message      Integral           1.0                             True\n",
       "3        Day Mins    Fractional           1.0                             True\n",
       "4       Day Calls      Integral           1.0                             True\n",
       "5        Eve Mins    Fractional           1.0                             True\n",
       "6       Eve Calls      Integral           1.0                             True\n",
       "7      Night Mins    Fractional           1.0                             True\n",
       "8     Night Calls      Integral           1.0                             True\n",
       "9       Intl Mins    Fractional           1.0                             True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "constraints_df = pd.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1fea8",
   "metadata": {
    "papermill": {
     "duration": 0.049354,
     "end_time": "2022-04-18T00:29:47.491527",
     "exception": false,
     "start_time": "2022-04-18T00:29:47.442173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Analyze collected data for data quality issues\n",
    "\n",
    "When you have collected the data above, analyze and monitor the data with Monitoring Schedules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d11a9",
   "metadata": {
    "papermill": {
     "duration": 0.049273,
     "end_time": "2022-04-18T00:29:47.590172",
     "exception": false,
     "start_time": "2022-04-18T00:29:47.540899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create a schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc1c301f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:47.702041Z",
     "iopub.status.busy": "2022-04-18T00:29:47.701315Z",
     "iopub.status.idle": "2022-04-18T00:29:47.906167Z",
     "shell.execute_reply": "2022-04-18T00:29:47.906567Z"
    },
    "papermill": {
     "duration": 0.267475,
     "end_time": "2022-04-18T00:29:47.906709",
     "exception": false,
     "start_time": "2022-04-18T00:29:47.639234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:52:03] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:52:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=341182;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=577168;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload some test scripts to the S3 bucket for pre- and post-processing\n",
    "bucket = boto3.Session().resource(\"s3\").Bucket(bucket)\n",
    "bucket.Object(code_prefix + \"/preprocessor.py\").upload_file(\"preprocessor.py\")\n",
    "bucket.Object(code_prefix + \"/postprocessor.py\").upload_file(\"postprocessor.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142c2be",
   "metadata": {
    "papermill": {
     "duration": 0.050333,
     "end_time": "2022-04-18T00:29:48.008206",
     "exception": false,
     "start_time": "2022-04-18T00:29:47.957873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can create a model monitoring schedule for the endpoint created earlier. Use the baseline resources (constraints and statistics) to compare against the realtime traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7889de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:48.112871Z",
     "iopub.status.busy": "2022-04-18T00:29:48.112310Z",
     "iopub.status.idle": "2022-04-18T00:29:48.725136Z",
     "shell.execute_reply": "2022-04-18T00:29:48.725519Z"
    },
    "papermill": {
     "duration": 0.667743,
     "end_time": "2022-04-18T00:29:48.725674",
     "exception": false,
     "start_time": "2022-04-18T00:29:48.057931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:57:20] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> The endpoint attribute has been renamed in sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.            <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:57:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m The endpoint attribute has been renamed in sagemaker>=\u001b[1;36m2\u001b[0m.            \u001b]8;id=54;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=697749;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:57:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating Monitoring Schedule with name:                       <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#1560\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1560</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:57:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating Monitoring Schedule with name:                       \u001b]8;id=303071;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=664531;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#1560\u001b\\\u001b[2m1560\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m2\u001b[0m \u001b[2m                        \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m                                                             \u001b[2m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "mon_schedule_name = \"DEMO-xgb-churn-pred-model-monitor-schedule-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    # record_preprocessor_script=pre_processor_script,\n",
    "    post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556ecf8",
   "metadata": {
    "papermill": {
     "duration": 0.049771,
     "end_time": "2022-04-18T00:29:48.825958",
     "exception": false,
     "start_time": "2022-04-18T00:29:48.776187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Start generating some artificial traffic\n",
    "The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23e81c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:48.933021Z",
     "iopub.status.busy": "2022-04-18T00:29:48.932245Z",
     "iopub.status.idle": "2022-04-18T00:29:48.937734Z",
     "shell.execute_reply": "2022-04-18T00:29:48.938102Z"
    },
    "papermill": {
     "duration": 0.06214,
     "end_time": "2022-04-18T00:29:48.938258",
     "exception": false,
     "start_time": "2022-04-18T00:29:48.876118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 12:58:29] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> The endpoint attribute has been renamed in sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.            <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 12:58:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m The endpoint attribute has been renamed in sagemaker>=\u001b[1;36m2\u001b[0m.            \u001b]8;id=914102;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=493227;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "endpoint_name = predictor.endpoint\n",
    "runtime_client = sm_session.sagemaker_runtime_client\n",
    "\n",
    "\n",
    "# (just repeating code from above for convenience/ able to run this section independently)\n",
    "def invoke_endpoint(ep_name, file_name, runtime_client):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = runtime_client.invoke_endpoint(\n",
    "                EndpointName=ep_name, ContentType=\"text/csv\", Body=payload\n",
    "            )\n",
    "            response[\"Body\"].read()\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        try:\n",
    "            invoke_endpoint(endpoint_name, \"test_data/test-dataset-input-cols.csv\", runtime_client)\n",
    "        except runtime_client.exceptions.ValidationError:\n",
    "            pass\n",
    "\n",
    "\n",
    "thread = Thread(target=invoke_endpoint_forever)\n",
    "thread.start()\n",
    "\n",
    "# Note that you need to stop the kernel to stop the invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22785b69",
   "metadata": {
    "papermill": {
     "duration": 0.050394,
     "end_time": "2022-04-18T00:29:49.042351",
     "exception": false,
     "start_time": "2022-04-18T00:29:48.991957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Describe and inspect the schedule\n",
    "Once you describe, observe that the MonitoringScheduleStatus changes to Scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d272369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:49.148331Z",
     "iopub.status.busy": "2022-04-18T00:29:49.147784Z",
     "iopub.status.idle": "2022-04-18T00:29:49.186670Z",
     "shell.execute_reply": "2022-04-18T00:29:49.187047Z"
    },
    "papermill": {
     "duration": 0.094778,
     "end_time": "2022-04-18T00:29:49.187187",
     "exception": false,
     "start_time": "2022-04-18T00:29:49.092409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Scheduled\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fe71d",
   "metadata": {
    "papermill": {
     "duration": 0.050423,
     "end_time": "2022-04-18T00:29:49.289400",
     "exception": false,
     "start_time": "2022-04-18T00:29:49.238977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### List executions\n",
    "The schedule starts jobs at the previously specified intervals. Here, you list the latest five executions. Note that if you are kicking this off after creating the hourly schedule, you might find the executions empty. You might have to wait until you cross the hour boundary (in UTC) to see executions kick off. The code below has the logic for waiting.\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule your execution. You might see your execution start in anywhere from zero to ~20 minutes from the hour boundary. This is expected and done for load balancing in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a7494cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T00:29:49.396118Z",
     "iopub.status.busy": "2022-04-18T00:29:49.395608Z",
     "iopub.status.idle": "2022-04-18T01:10:54.022149Z",
     "shell.execute_reply": "2022-04-18T01:10:54.022560Z"
    },
    "papermill": {
     "duration": 2464.682976,
     "end_time": "2022-04-18T01:10:54.022704",
     "exception": false,
     "start_time": "2022-04-18T00:29:49.339728",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:01:18] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:01:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=492082;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=263701;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above that begins executions ON the hour (plus 0-20 min buffer.\n",
      "We will have to wait till we hit the hour...\n",
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:02:20] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:02:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=157952;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=583064;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:03:20] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:03:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=529432;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=814818;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:04:22] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:04:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=396870;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=742207;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:05:23] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:05:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=745989;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51881;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:06:24] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:06:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=163536;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=900729;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:07:25] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:07:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=47537;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=709380;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:08:26] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:08:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=453860;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=118268;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:09:27] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:09:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=962966;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=348482;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:10:28] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:10:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=956739;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=701123;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:11:29] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:11:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=385988;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=43262;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:12:30] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:12:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=748021;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291806;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:13:31] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:13:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=989580;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=199643;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:14:32] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:14:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=250987;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=809212;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:15:33] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:15:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=169555;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=249995;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:16:35] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:16:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=488190;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=132551;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:17:36] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:17:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=677532;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=137146;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:18:37] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:18:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=756335;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=455776;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:19:37] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:19:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=970496;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=278351;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:20:38] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:20:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=558559;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=177457;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:21:40] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:21:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=930443;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=768544;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:22:41] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:22:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=664182;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=434152;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:23:42] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:23:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=936824;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=885125;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:24:43] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:24:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=495710;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=450892;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:25:44] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:25:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=765146;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=139137;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:26:45] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:26:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=544840;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988065;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:27:46] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:27:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=494719;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=111216;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:28:47] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:28:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=128083;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631103;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:29:48] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:29:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=392166;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=312066;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:30:49] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:30:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=637061;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=488890;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:31:50] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:31:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=8132;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=70491;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:32:52] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No executions found for schedule. monitoring_schedule_name:    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:32:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No executions found for schedule. monitoring_schedule_name:    \u001b]8;id=72552;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=959727;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#777\u001b\\\u001b[2m777\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the first execution to happen...\n"
     ]
    }
   ],
   "source": [
    "mon_executions = my_default_monitor.list_executions()\n",
    "print(\n",
    "    \"We created a hourly schedule above that begins executions ON the hour (plus 0-20 min buffer.\\nWe will have to wait till we hit the hour...\"\n",
    ")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the first execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_default_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e5a91",
   "metadata": {
    "papermill": {
     "duration": 0.059309,
     "end_time": "2022-04-18T01:10:54.142040",
     "exception": false,
     "start_time": "2022-04-18T01:10:54.082731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Inspect a specific execution (latest execution)\n",
    "In the previous cell, you picked up the latest completed or failed scheduled execution. Here are the possible terminal states and what each of them mean: \n",
    "* `Completed` - The monitoring execution completed and no issues were found in the violations report.\n",
    "* `CompletedWithViolations` - The execution completed, but constraint violations were detected.\n",
    "* `Failed` - The monitoring execution failed, maybe due to client error (perhaps incorrect role premissions) or infrastructure issues. Further examination of `FailureReason` and `ExitMessage` is necessary to identify what exactly happened.\n",
    "* `Stopped` - The job exceeded max runtime or was manually stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d550a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:10:54.266146Z",
     "iopub.status.busy": "2022-04-18T01:10:54.265580Z",
     "iopub.status.idle": "2022-04-18T01:15:40.304016Z",
     "shell.execute_reply": "2022-04-18T01:15:40.303589Z"
    },
    "papermill": {
     "duration": 286.102546,
     "end_time": "2022-04-18T01:15:40.304129",
     "exception": false,
     "start_time": "2022-04-18T01:10:54.201583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............!Latest execution status: Completed\n",
      "Latest execution result: CompletedWithViolations: Job completed successfully with 60 violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1]  # Latest execution's index is -1, second to last is -2, etc\n",
    "time.sleep(60)\n",
    "latest_execution.wait(logs=False)\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()[\"ProcessingJobStatus\"]))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()[\"ExitMessage\"]))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if latest_job[\"ProcessingJobStatus\"] != \"Completed\":\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34b857e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:15:40.445435Z",
     "iopub.status.busy": "2022-04-18T01:15:40.444884Z",
     "iopub.status.idle": "2022-04-18T01:15:40.447659Z",
     "shell.execute_reply": "2022-04-18T01:15:40.447208Z"
    },
    "papermill": {
     "duration": 0.074909,
     "end_time": "2022-04-18T01:15:40.447784",
     "exception": false,
     "start_time": "2022-04-18T01:15:40.372875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://sagemaker-us-east-1-266735799838/sagemaker/ModelMonitor/reports/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/DEMO-xgb-churn-pred-model-monitor-schedule-2025-02-20-07-27-20/2025/02/20/08\n"
     ]
    }
   ],
   "source": [
    "report_uri = latest_execution.output.destination\n",
    "print(\"Report Uri: {}\".format(report_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4070b1",
   "metadata": {
    "papermill": {
     "duration": 0.068521,
     "end_time": "2022-04-18T01:15:40.585134",
     "exception": false,
     "start_time": "2022-04-18T01:15:40.516613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### List the generated reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "227c215b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:15:40.736923Z",
     "iopub.status.busy": "2022-04-18T01:15:40.728273Z",
     "iopub.status.idle": "2022-04-18T01:15:40.987597Z",
     "shell.execute_reply": "2022-04-18T01:15:40.987996Z"
    },
    "papermill": {
     "duration": 0.33424,
     "end_time": "2022-04-18T01:15:40.988140",
     "exception": false,
     "start_time": "2022-04-18T01:15:40.653900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report bucket: sagemaker-us-east-1-266735799838\n",
      "Report key: sagemaker/ModelMonitor/reports/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/DEMO-xgb-churn-pred-model-monitor-schedule-2025-02-20-07-27-20/2025/02/20/08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:39:03] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:39:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=401791;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=197292;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Report Files:\n",
      "sagemaker/ModelMonitor/reports/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/DEMO-xgb-churn-pred-model-monitor-schedule-2025-02-20-07-27-20/2025/02/20/08/constraint_violations.json\n",
      " sagemaker/ModelMonitor/reports/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/DEMO-xgb-churn-pred-model-monitor-schedule-2025-02-20-07-27-20/2025/02/20/08/constraints.json\n",
      " sagemaker/ModelMonitor/reports/DEMO-xgb-churn-pred-model-monitor-2025-02-20-06-07-30/DEMO-xgb-churn-pred-model-monitor-schedule-2025-02-20-07-27-20/2025/02/20/08/statistics.json\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip(\"/\")\n",
    "print(\"Report bucket: {}\".format(report_bucket))\n",
    "print(\"Report key: {}\".format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client(\"s3\")\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abe9e0",
   "metadata": {
    "papermill": {
     "duration": 0.069468,
     "end_time": "2022-04-18T01:15:41.127235",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.057767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Violations report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77403388",
   "metadata": {
    "papermill": {
     "duration": 0.070022,
     "end_time": "2022-04-18T01:15:41.266951",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.196929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Any violations compared to the baseline are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "111944d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:15:41.411758Z",
     "iopub.status.busy": "2022-04-18T01:15:41.411186Z",
     "iopub.status.idle": "2022-04-18T01:15:41.543054Z",
     "shell.execute_reply": "2022-04-18T01:15:41.543448Z"
    },
    "papermill": {
     "duration": 0.206895,
     "end_time": "2022-04-18T01:15:41.543590",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.336695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State_IA</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State_PA</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State_AZ</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>State_MI</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Area Code_415</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>State_NM</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>State_DC</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VMail Plan_no</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Churn</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>State_AK</td>\n",
       "      <td>data_type_check</td>\n",
       "      <td>Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_name constraint_check_type  \\\n",
       "0       State_IA       data_type_check   \n",
       "1       State_PA       data_type_check   \n",
       "2       State_AZ       data_type_check   \n",
       "3       State_MI       data_type_check   \n",
       "4  Area Code_415       data_type_check   \n",
       "5       State_NM       data_type_check   \n",
       "6       State_DC       data_type_check   \n",
       "7  VMail Plan_no       data_type_check   \n",
       "8          Churn       data_type_check   \n",
       "9       State_AK       data_type_check   \n",
       "\n",
       "                                                                                                                                            description  \n",
       "0  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "1  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "2  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "3  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "4  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "5  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "6  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "7  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  \n",
       "8                Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 0.0% of data is Integral.  \n",
       "9  Data type match requirement is not met. Expected data type: Integral, Expected match: 100.0%. Observed: Only 99.67234600262124% of data is Integral.  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations = my_default_monitor.latest_monitoring_constraint_violations()\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "constraints_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de159706",
   "metadata": {
    "papermill": {
     "duration": 0.070228,
     "end_time": "2022-04-18T01:15:41.683659",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.613431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Other commands\n",
    "We can also start and stop the monitoring schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70749848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:15:41.827114Z",
     "iopub.status.busy": "2022-04-18T01:15:41.826633Z",
     "iopub.status.idle": "2022-04-18T01:15:41.828553Z",
     "shell.execute_reply": "2022-04-18T01:15:41.828938Z"
    },
    "papermill": {
     "duration": 0.075182,
     "end_time": "2022-04-18T01:15:41.829067",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.753885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:40:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Stopping Monitoring Schedule with name:                                <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2225</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:40:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Stopping Monitoring Schedule with name:                                \u001b]8;id=931902;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110791;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2225\u001b\\\u001b[2m2225\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_default_monitor.stop_monitoring_schedule()\n",
    "# my_default_monitor.start_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8713a6",
   "metadata": {
    "papermill": {
     "duration": 0.070556,
     "end_time": "2022-04-18T01:15:41.969642",
     "exception": false,
     "start_time": "2022-04-18T01:15:41.899086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Delete resources\n",
    "\n",
    "You can keep your endpoint running to continue capturing data. If you do not plan to collect more data or use this endpoint further, delete the endpoint to avoid incurring additional charges. Note that deleting your endpoint does not delete the data that was captured during the model invocations. That data persists in Amazon S3 until you delete it yourself.\n",
    "\n",
    "You need to delete the schedule before deleting the model and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af984eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:15:42.144557Z",
     "iopub.status.busy": "2022-04-18T01:15:42.144042Z",
     "iopub.status.idle": "2022-04-18T01:17:02.831114Z",
     "shell.execute_reply": "2022-04-18T01:17:02.831629Z"
    },
    "papermill": {
     "duration": 80.76217,
     "end_time": "2022-04-18T01:17:02.831829",
     "exception": false,
     "start_time": "2022-04-18T01:15:42.069659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:40:52] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Stopping Monitoring Schedule with name:                                <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2225</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:40:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Stopping Monitoring Schedule with name:                                \u001b]8;id=78067;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439090;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2225\u001b\\\u001b[2m2225\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:40:58] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting Monitoring Schedule with name:                                <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2237\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2237</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-schedule-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:40:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting Monitoring Schedule with name:                                \u001b]8;id=386536;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=207010;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#2237\u001b\\\u001b[2m2237\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-schedule-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m27\u001b[0m-\u001b[1;36m20\u001b[0m         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:41:04] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting Data Quality Job Definition with name:               <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_monitoring.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#2461\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2461</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         data-quality-job-definition-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-20-07-27-22-980           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:41:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting Data Quality Job Definition with name:               \u001b]8;id=497733;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b\\\u001b[2mmodel_monitoring.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=562124;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/model_monitor/model_monitoring.py#2461\u001b\\\u001b[2m2461\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         data-quality-job-definition-\u001b[1;36m2025\u001b[0m-02-20-07-27-22-980           \u001b[2m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_default_monitor.stop_monitoring_schedule()\n",
    "my_default_monitor.delete_monitoring_schedule()\n",
    "time.sleep(60)  # Wait for the deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5d93a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:17:02.995062Z",
     "iopub.status.busy": "2022-04-18T01:17:02.994531Z",
     "iopub.status.idle": "2022-04-18T01:17:03.202044Z",
     "shell.execute_reply": "2022-04-18T01:17:03.202448Z"
    },
    "papermill": {
     "duration": 0.291003,
     "end_time": "2022-04-18T01:17:03.202589",
     "exception": false,
     "start_time": "2022-04-18T01:17:02.911586",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:42:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting model with name: sagemaker-xgboost-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-02-20-06-07-30-626    <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#5226\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5226</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:42:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting model with name: sagemaker-xgboost-\u001b[1;36m2025\u001b[0m-02-20-06-07-30-626    \u001b]8;id=373942;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=477851;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#5226\u001b\\\u001b[2m5226\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fd0f570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T01:17:03.360478Z",
     "iopub.status.busy": "2022-04-18T01:17:03.359925Z",
     "iopub.status.idle": "2022-04-18T01:17:03.565182Z",
     "shell.execute_reply": "2022-04-18T01:17:03.565688Z"
    },
    "papermill": {
     "duration": 0.290093,
     "end_time": "2022-04-18T01:17:03.565886",
     "exception": false,
     "start_time": "2022-04-18T01:17:03.275793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:42:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4865\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4865</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:42:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=958060;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=329064;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4865\u001b\\\u001b[2m4865\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m30\u001b[0m                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/20/25 13:42:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4855\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4855</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DEMO-xgb-churn-pred-model-monitor-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/20/25 13:42:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=296996;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=115114;file:///opt/anaconda3/envs/model-monitor/lib/python3.12/site-packages/sagemaker/session.py#4855\u001b\\\u001b[2m4855\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DEMO-xgb-churn-pred-model-monitor-\u001b[1;36m2025\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m20\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m30\u001b[0m                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/deploy_and_monitor|sm-model_monitor_introduction|sm-model_monitor_introduction.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "model-monitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "papermill": {
   "default_parameters": {},
   "duration": 3833.130815,
   "end_time": "2022-04-18T01:17:06.266500",
   "environment_variables": {},
   "exception": null,
   "input_path": "SageMaker-ModelMonitoring.ipynb",
   "output_path": "/opt/ml/processing/output/SageMaker-ModelMonitoring-2022-04-18-00-08-24.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:000000000000:1234abcd-12ab-34cd-56ef-1234567890ab"
   },
   "start_time": "2022-04-18T00:13:13.135685",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
